{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "본 문서는 아래 사이트에서 제공되는 설명 및 코드를 번역 및 참고하였습니다. \n",
        "\n",
        "* https://python.langchain.com/"
      ],
      "metadata": {
        "id": "CjZxYI5cOBgc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 사용자키 준비\n",
        "\n",
        "* https://openai.com/ 에서 OPENAI_API_KEY 키를 발급받아주세요.\n",
        "* https://serpapi.com/ 에서 SERPAPI_API_KEY 키를 발급받아주세요."
      ],
      "metadata": {
        "id": "hz_4SL4ghuFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"741...\""
      ],
      "metadata": {
        "id": "6Tz11WhvICS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 패키지 설치"
      ],
      "metadata": {
        "id": "PbukDq2dhxel"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fWmF0RdHlb_",
        "outputId": "93754e77-de38-41ed-bc85-bb7941cc1824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.9/dist-packages (0.0.142)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.9/dist-packages (from langchain) (2.28.2)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.9/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.4.47)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.9/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: gptcache>=0.1.7 in /usr/local/lib/python3.9/dist-packages (from langchain) (0.1.14)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.9/dist-packages (from langchain) (0.5.7)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.9/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.9/dist-packages (from gptcache>=0.1.7->langchain) (0.27.4)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.9/dist-packages (from gptcache>=0.1.7->langchain) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.9/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai->gptcache>=0.1.7->langchain) (4.65.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.9/dist-packages (0.3.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from tiktoken) (2.28.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.9/dist-packages (0.27.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.28.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.9/dist-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from google-search-results) (2.28.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->google-search-results) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->google-search-results) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->google-search-results) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->google-search-results) (2.0.12)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.9/dist-packages (0.3.21)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.9/dist-packages (from chromadb) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.9/dist-packages (from chromadb) (1.22.4)\n",
            "Requirement already satisfied: hnswlib>=0.7 in /usr/local/lib/python3.9/dist-packages (from chromadb) (0.7.0)\n",
            "Requirement already satisfied: duckdb>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from chromadb) (0.7.1)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.9/dist-packages (from chromadb) (2.28.2)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.9/dist-packages (from chromadb) (1.5.3)\n",
            "Requirement already satisfied: fastapi>=0.85.1 in /usr/local/lib/python3.9/dist-packages (from chromadb) (0.95.1)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.9/dist-packages (from chromadb) (0.21.1)\n",
            "Requirement already satisfied: sentence-transformers>=2.2.2 in /usr/local/lib/python3.9/dist-packages (from chromadb) (2.2.2)\n",
            "Requirement already satisfied: clickhouse-connect>=0.5.7 in /usr/local/lib/python3.9/dist-packages (from chromadb) (0.5.20)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.9/dist-packages (from chromadb) (1.10.7)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.9/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.7.1)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.9/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (0.21.0)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.9/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (4.3.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.12.7)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.9/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.15)\n",
            "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /usr/local/lib/python3.9/dist-packages (from fastapi>=0.85.1->chromadb) (0.26.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.9/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic>=1.9->chromadb) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.28->chromadb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.28->chromadb) (3.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (3.8.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (4.28.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (1.2.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (0.15.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (4.65.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (0.1.98)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (0.13.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (2.0.0+cu118)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.5.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (3.11.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.9/dist-packages (from starlette<0.27.0,>=0.26.1->fastapi>=0.85.1->chromadb) (3.6.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (3.1.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (16.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (0.13.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->sentence-transformers>=2.2.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->sentence-transformers>=2.2.2->chromadb) (8.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.9/dist-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi>=0.85.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.9/dist-packages (1.7.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain  # 자연어 처리 및 기계 번역에 사용됩니다.\n",
        "!pip install tiktoken   # 텍스트 토큰화에 사용됩니다.\n",
        "!pip install openai     # OpenAI API와 상호작용하는 데 사용됩니다.\n",
        "!pip install google-search-results # 구글 검색 결과를 가져오는 데 사용됩니다.\n",
        "!pip install chromadb   # 벡터 데이터베이스를 이용하는 데 사용됩니다.\n",
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 개인비서 - BabyAGI"
      ],
      "metadata": {
        "id": "faxZ9_jRsm2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import deque\n",
        "from typing import Dict, List, Optional, Any\n",
        "\n",
        "from langchain import LLMChain, OpenAI, PromptTemplate\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.llms import BaseLLM\n",
        "from langchain.vectorstores.base import VectorStore\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.chains.base import Chain"
      ],
      "metadata": {
        "id": "zs17oXhfsxvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.docstore import InMemoryDocstore"
      ],
      "metadata": {
        "id": "tF3chB1Gsztx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your embedding model\n",
        "embeddings_model = OpenAIEmbeddings()\n",
        "# Initialize the vectorstore as empty\n",
        "import faiss\n",
        "\n",
        "embedding_size = 1536\n",
        "index = faiss.IndexFlatL2(embedding_size)\n",
        "vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})"
      ],
      "metadata": {
        "id": "C15dDjc4s1aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TaskCreationChain(LLMChain):\n",
        "    \"\"\"Chain to generates tasks.\"\"\"\n",
        "\n",
        "    @classmethod\n",
        "    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n",
        "        \"\"\"Get the response parser.\"\"\"\n",
        "        task_creation_template = (\n",
        "            \"You are a task creation AI that uses the result of an execution agent\"\n",
        "            \" to create new tasks with the following objective: {objective},\"\n",
        "            \" The last completed task has the result: {result}.\"\n",
        "            \" This result was based on this task description: {task_description}.\"\n",
        "            \" These are incomplete tasks: {incomplete_tasks}.\"\n",
        "            \" Based on the result, create new tasks to be completed\"\n",
        "            \" by the AI system that do not overlap with incomplete tasks.\"\n",
        "            \" Return the tasks as an array.\"\n",
        "        )\n",
        "        prompt = PromptTemplate(\n",
        "            template=task_creation_template,\n",
        "            input_variables=[\n",
        "                \"result\",\n",
        "                \"task_description\",\n",
        "                \"incomplete_tasks\",\n",
        "                \"objective\",\n",
        "            ],\n",
        "        )\n",
        "        return cls(prompt=prompt, llm=llm, verbose=verbose)"
      ],
      "metadata": {
        "id": "XxqsFu1Is2-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TaskPrioritizationChain(LLMChain):\n",
        "    \"\"\"Chain to prioritize tasks.\"\"\"\n",
        "\n",
        "    @classmethod\n",
        "    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n",
        "        \"\"\"Get the response parser.\"\"\"\n",
        "        task_prioritization_template = (\n",
        "            \"You are a task prioritization AI tasked with cleaning the formatting of and reprioritizing\"\n",
        "            \" the following tasks: {task_names}.\"\n",
        "            \" Consider the ultimate objective of your team: {objective}.\"\n",
        "            \" Do not remove any tasks. Return the result as a numbered list, like:\"\n",
        "            \" #. First task\"\n",
        "            \" #. Second task\"\n",
        "            \" Start the task list with number {next_task_id}.\"\n",
        "        )\n",
        "        prompt = PromptTemplate(\n",
        "            template=task_prioritization_template,\n",
        "            input_variables=[\"task_names\", \"next_task_id\", \"objective\"],\n",
        "        )\n",
        "        return cls(prompt=prompt, llm=llm, verbose=verbose)"
      ],
      "metadata": {
        "id": "i_LhFMqms4TG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExecutionChain(LLMChain):\n",
        "    \"\"\"Chain to execute tasks.\"\"\"\n",
        "\n",
        "    @classmethod\n",
        "    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n",
        "        \"\"\"Get the response parser.\"\"\"\n",
        "        execution_template = (\n",
        "            \"You are an AI who performs one task based on the following objective: {objective}.\"\n",
        "            \" Take into account these previously completed tasks: {context}.\"\n",
        "            \" Your task: {task}.\"\n",
        "            \" Response:\"\n",
        "        )\n",
        "        prompt = PromptTemplate(\n",
        "            template=execution_template,\n",
        "            input_variables=[\"objective\", \"context\", \"task\"],\n",
        "        )\n",
        "        return cls(prompt=prompt, llm=llm, verbose=verbose)"
      ],
      "metadata": {
        "id": "MCxF1P8qs51R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_next_task(\n",
        "    task_creation_chain: LLMChain,\n",
        "    result: Dict,\n",
        "    task_description: str,\n",
        "    task_list: List[str],\n",
        "    objective: str,\n",
        ") -> List[Dict]:\n",
        "    \"\"\"Get the next task.\"\"\"\n",
        "    incomplete_tasks = \", \".join(task_list)\n",
        "    response = task_creation_chain.run(\n",
        "        result=result,\n",
        "        task_description=task_description,\n",
        "        incomplete_tasks=incomplete_tasks,\n",
        "        objective=objective,\n",
        "    )\n",
        "    new_tasks = response.split(\"\\n\")\n",
        "    return [{\"task_name\": task_name} for task_name in new_tasks if task_name.strip()]"
      ],
      "metadata": {
        "id": "wKpojMTvs7qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prioritize_tasks(\n",
        "    task_prioritization_chain: LLMChain,\n",
        "    this_task_id: int,\n",
        "    task_list: List[Dict],\n",
        "    objective: str,\n",
        ") -> List[Dict]:\n",
        "    \"\"\"Prioritize tasks.\"\"\"\n",
        "    task_names = [t[\"task_name\"] for t in task_list]\n",
        "    next_task_id = int(this_task_id) + 1\n",
        "    response = task_prioritization_chain.run(\n",
        "        task_names=task_names, next_task_id=next_task_id, objective=objective\n",
        "    )\n",
        "    new_tasks = response.split(\"\\n\")\n",
        "    prioritized_task_list = []\n",
        "    for task_string in new_tasks:\n",
        "        if not task_string.strip():\n",
        "            continue\n",
        "        task_parts = task_string.strip().split(\".\", 1)\n",
        "        if len(task_parts) == 2:\n",
        "            task_id = task_parts[0].strip()\n",
        "            task_name = task_parts[1].strip()\n",
        "            prioritized_task_list.append({\"task_id\": task_id, \"task_name\": task_name})\n",
        "    return prioritized_task_list"
      ],
      "metadata": {
        "id": "cQKLrSzMs9C3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_top_tasks(vectorstore, query: str, k: int) -> List[str]:\n",
        "    \"\"\"Get the top k tasks based on the query.\"\"\"\n",
        "    results = vectorstore.similarity_search_with_score(query, k=k)\n",
        "    if not results:\n",
        "        return []\n",
        "    sorted_results, _ = zip(*sorted(results, key=lambda x: x[1], reverse=True))\n",
        "    return [str(item.metadata[\"task\"]) for item in sorted_results]\n",
        "\n",
        "\n",
        "def execute_task(\n",
        "    vectorstore, execution_chain: LLMChain, objective: str, task: str, k: int = 5\n",
        ") -> str:\n",
        "    \"\"\"Execute a task.\"\"\"\n",
        "    context = _get_top_tasks(vectorstore, query=objective, k=k)\n",
        "    return execution_chain.run(objective=objective, context=context, task=task)"
      ],
      "metadata": {
        "id": "gIAJU1v-s_B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BabyAGI(Chain, BaseModel):\n",
        "    \"\"\"Controller model for the BabyAGI agent.\"\"\"\n",
        "\n",
        "    task_list: deque = Field(default_factory=deque)\n",
        "    task_creation_chain: TaskCreationChain = Field(...)\n",
        "    task_prioritization_chain: TaskPrioritizationChain = Field(...)\n",
        "    execution_chain: ExecutionChain = Field(...)\n",
        "    task_id_counter: int = Field(1)\n",
        "    vectorstore: VectorStore = Field(init=False)\n",
        "    max_iterations: Optional[int] = None\n",
        "\n",
        "    class Config:\n",
        "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
        "\n",
        "        arbitrary_types_allowed = True\n",
        "\n",
        "    def add_task(self, task: Dict):\n",
        "        self.task_list.append(task)\n",
        "\n",
        "    def print_task_list(self):\n",
        "        print(\"\\033[95m\\033[1m\" + \"\\n*****TASK LIST*****\\n\" + \"\\033[0m\\033[0m\")\n",
        "        for t in self.task_list:\n",
        "            print(str(t[\"task_id\"]) + \": \" + t[\"task_name\"])\n",
        "\n",
        "    def print_next_task(self, task: Dict):\n",
        "        print(\"\\033[92m\\033[1m\" + \"\\n*****NEXT TASK*****\\n\" + \"\\033[0m\\033[0m\")\n",
        "        print(str(task[\"task_id\"]) + \": \" + task[\"task_name\"])\n",
        "\n",
        "    def print_task_result(self, result: str):\n",
        "        print(\"\\033[93m\\033[1m\" + \"\\n*****TASK RESULT*****\\n\" + \"\\033[0m\\033[0m\")\n",
        "        print(result)\n",
        "\n",
        "    @property\n",
        "    def input_keys(self) -> List[str]:\n",
        "        return [\"objective\"]\n",
        "\n",
        "    @property\n",
        "    def output_keys(self) -> List[str]:\n",
        "        return []\n",
        "\n",
        "    def _call(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Run the agent.\"\"\"\n",
        "        objective = inputs[\"objective\"]\n",
        "        first_task = inputs.get(\"first_task\", \"Make a todo list\")\n",
        "        self.add_task({\"task_id\": 1, \"task_name\": first_task})\n",
        "        num_iters = 0\n",
        "        while True:\n",
        "            if self.task_list:\n",
        "                self.print_task_list()\n",
        "\n",
        "                # Step 1: Pull the first task\n",
        "                task = self.task_list.popleft()\n",
        "                self.print_next_task(task)\n",
        "\n",
        "                # Step 2: Execute the task\n",
        "                result = execute_task(\n",
        "                    self.vectorstore, self.execution_chain, objective, task[\"task_name\"]\n",
        "                )\n",
        "                this_task_id = int(task[\"task_id\"])\n",
        "                self.print_task_result(result)\n",
        "\n",
        "                # Step 3: Store the result in Pinecone\n",
        "                result_id = f\"result_{task['task_id']}\"\n",
        "                self.vectorstore.add_texts(\n",
        "                    texts=[result],\n",
        "                    metadatas=[{\"task\": task[\"task_name\"]}],\n",
        "                    ids=[result_id],\n",
        "                )\n",
        "\n",
        "                # Step 4: Create new tasks and reprioritize task list\n",
        "                new_tasks = get_next_task(\n",
        "                    self.task_creation_chain,\n",
        "                    result,\n",
        "                    task[\"task_name\"],\n",
        "                    [t[\"task_name\"] for t in self.task_list],\n",
        "                    objective,\n",
        "                )\n",
        "                for new_task in new_tasks:\n",
        "                    self.task_id_counter += 1\n",
        "                    new_task.update({\"task_id\": self.task_id_counter})\n",
        "                    self.add_task(new_task)\n",
        "                self.task_list = deque(\n",
        "                    prioritize_tasks(\n",
        "                        self.task_prioritization_chain,\n",
        "                        this_task_id,\n",
        "                        list(self.task_list),\n",
        "                        objective,\n",
        "                    )\n",
        "                )\n",
        "            num_iters += 1\n",
        "            if self.max_iterations is not None and num_iters == self.max_iterations:\n",
        "                print(\n",
        "                    \"\\033[91m\\033[1m\" + \"\\n*****TASK ENDING*****\\n\" + \"\\033[0m\\033[0m\"\n",
        "                )\n",
        "                break\n",
        "        return {}\n",
        "\n",
        "    @classmethod\n",
        "    def from_llm(\n",
        "        cls, llm: BaseLLM, vectorstore: VectorStore, verbose: bool = False, **kwargs\n",
        "    ) -> \"BabyAGI\":\n",
        "        \"\"\"Initialize the BabyAGI Controller.\"\"\"\n",
        "        task_creation_chain = TaskCreationChain.from_llm(llm, verbose=verbose)\n",
        "        task_prioritization_chain = TaskPrioritizationChain.from_llm(\n",
        "            llm, verbose=verbose\n",
        "        )\n",
        "        execution_chain = ExecutionChain.from_llm(llm, verbose=verbose)\n",
        "        return cls(\n",
        "            task_creation_chain=task_creation_chain,\n",
        "            task_prioritization_chain=task_prioritization_chain,\n",
        "            execution_chain=execution_chain,\n",
        "            vectorstore=vectorstore,\n",
        "            **kwargs,\n",
        "        )"
      ],
      "metadata": {
        "id": "APcjd4UztA0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OBJECTIVE = \"Write a weather report for SF today\"\n",
        "llm = OpenAI(temperature=0)\n",
        "# Logging of LLMChains\n",
        "verbose = False\n",
        "# If None, will keep on going forever\n",
        "max_iterations: Optional[int] = 3\n",
        "baby_agi = BabyAGI.from_llm(\n",
        "    llm=llm, vectorstore=vectorstore, verbose=verbose, max_iterations=max_iterations\n",
        ")\n",
        "baby_agi({\"objective\": OBJECTIVE})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8IQgQPAtCsz",
        "outputId": "60c895e4-a4b0-4938-aff1-d87e910c4da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[95m\u001b[1m\n",
            "*****TASK LIST*****\n",
            "\u001b[0m\u001b[0m\n",
            "1: Make a todo list\n",
            "\u001b[92m\u001b[1m\n",
            "*****NEXT TASK*****\n",
            "\u001b[0m\u001b[0m\n",
            "1: Make a todo list\n",
            "\u001b[93m\u001b[1m\n",
            "*****TASK RESULT*****\n",
            "\u001b[0m\u001b[0m\n",
            "\n",
            "\n",
            "1. Check the current temperature in San Francisco\n",
            "2. Check the forecast for the day\n",
            "3. Check the humidity levels\n",
            "4. Check the wind speed and direction\n",
            "5. Check the UV index\n",
            "6. Check the air quality\n",
            "7. Check the sunrise and sunset times\n",
            "8. Check for any weather alerts or warnings\n",
            "9. Write the weather report\n",
            "\u001b[95m\u001b[1m\n",
            "*****TASK LIST*****\n",
            "\u001b[0m\u001b[0m\n",
            "2: Check the current temperature in San Francisco\n",
            "3: Check the forecast for the day\n",
            "4: Check the humidity levels\n",
            "5: Check the wind speed and direction\n",
            "6: Check the UV index\n",
            "7: Check the air quality\n",
            "8: Check for any weather alerts or warnings\n",
            "9: Check the sunrise and sunset times\n",
            "10: Research the historical weather data for San Francisco\n",
            "11: Research the average temperature for San Francisco in the current month\n",
            "12: Research the average temperature for San Francisco in the previous month\n",
            "13: Research the average temperature for San Francisco in the next month\n",
            "14: Research the average precipitation for San Francisco in the current month\n",
            "15: Research the average precipitation for San Francisco in the previous month\n",
            "16: Research the average precipitation for San Francisco in the next month\n",
            "17: Research the average wind speed for San Francisco in the current month\n",
            "18: Research the average wind speed for San Francisco in the previous month\n",
            "19: Research the average wind speed for San Francisco in the next month\n",
            "20: Research the average humidity for San Francisco in the current month\n",
            "21: Research the average humidity for San Francisco in the previous month\n",
            "\u001b[92m\u001b[1m\n",
            "*****NEXT TASK*****\n",
            "\u001b[0m\u001b[0m\n",
            "2: Check the current temperature in San Francisco\n",
            "\u001b[93m\u001b[1m\n",
            "*****TASK RESULT*****\n",
            "\u001b[0m\u001b[0m\n",
            "\n",
            "\n",
            "The current temperature in San Francisco is approximately 64 degrees Fahrenheit.\n",
            "\u001b[95m\u001b[1m\n",
            "*****TASK LIST*****\n",
            "\u001b[0m\u001b[0m\n",
            "3: Check the forecast for the day\n",
            "4: Check the humidity levels\n",
            "5: Check the wind speed and direction\n",
            "6: Check the UV index\n",
            "7: Check the air quality\n",
            "8: Check for any weather alerts or warnings\n",
            "9: Check the sunrise and sunset times\n",
            "10: Research the historical weather data for San Francisco\n",
            "11: Research the average temperature for San Francisco in the current month\n",
            "12: Research the average temperature for San Francisco in the previous month\n",
            "13: Research the average temperature for San Francisco in the next month\n",
            "14: Research the average precipitation for San Francisco in the current month\n",
            "15: Research the average precipitation for San Francisco in the previous month\n",
            "16: Research the average precipitation for San Francisco in the next month\n",
            "17: Research the average wind speed for San Francisco in the current month\n",
            "18: Research the average wind speed for San Francisco in the previous month\n",
            "19: Research the average wind speed for San Francisco in the next month\n",
            "20: Research the average humidity for San Francisco in the current month\n",
            "21: Research the average humidity for San Francisco in the previous month\n",
            "22: Compare the current temperature in San Francisco to the historical average temperature for the same day.\n",
            "23: Compare the current temperature in San\n",
            "\u001b[92m\u001b[1m\n",
            "*****NEXT TASK*****\n",
            "\u001b[0m\u001b[0m\n",
            "3: Check the forecast for the day\n",
            "\u001b[93m\u001b[1m\n",
            "*****TASK RESULT*****\n",
            "\u001b[0m\u001b[0m\n",
            "\n",
            "\n",
            "I will check the forecast for San Francisco today. According to the National Weather Service, the forecast for today is mostly sunny with a high of 68 degrees Fahrenheit and a low of 54 degrees Fahrenheit. There is a slight chance of showers in the evening.\n",
            "\u001b[91m\u001b[1m\n",
            "*****TASK ENDING*****\n",
            "\u001b[0m\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'objective': 'Write a weather report for SF today'}"
            ]
          },
          "metadata": {},
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 개인비서 - 사용자 정의 에이전트와 플러그인 검색\n",
        "\n",
        "AI 플러그인과 상호 작용할 수 있는 사용자 정의 에이전트를 구축하기 위해 두 가지 개념을 결합합니다:\n",
        "\n",
        "사용자 정의 에이전트와 검색: 이것은 임의의 많은 플러그인을 사용하여 작업을 시도할 때 유용한 많은 도구를 검색하는 개념을 소개합니다.\n",
        "\n",
        "자연어 API 체인: 이것은 OpenAPI 엔드포인트 주변에 자연어 래퍼를 만듭니다. 이것이 유용한 이유는 (1) 플러그인이 내부적으로 OpenAPI 엔드포인트를 사용하고, (2) NLAChain에 래핑하면 라우터 에이전트가 더 쉽게 호출할 수 있기 때문입니다.\n",
        "\n",
        "이 노트북에서 도입된 새로운 아이디어는 도구를 명시적으로 선택하는 것이 아니라 사용할 OpenAPI 사양을 선택하는 검색의 개념입니다. 그런 다음 해당 OpenAPI 사양에서 도구를 생성할 수 있습니다. 이것이 에이전트가 플러그인을 사용하도록 하려는 경우 사용 사례입니다. 플러그인을 먼저 선택한 다음 엔드포인트를 선택하는 것이 엔드포인트를 직접 선택하는 것보다 효율적일 수 있습니다. 이는 플러그인이 선택에 대한 더 유용한 정보를 포함할 수 있기 때문입니다."
      ],
      "metadata": {
        "id": "Y-SW7F8TAJ92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
        "from langchain.prompts import StringPromptTemplate\n",
        "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
        "from typing import List, Union\n",
        "from langchain.schema import AgentAction, AgentFinish\n",
        "from langchain.agents.agent_toolkits import NLAToolkit\n",
        "from langchain.tools.plugin import AIPlugin\n",
        "import re"
      ],
      "metadata": {
        "id": "QgjA7zuU_r4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "olST5WL5Aff-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urls = [\n",
        "    \"https://datasette.io/.well-known/ai-plugin.json\",\n",
        "    \"https://api.speak.com/.well-known/ai-plugin.json\",\n",
        "    \"https://www.wolframalpha.com/.well-known/ai-plugin.json\",\n",
        "    \"https://www.zapier.com/.well-known/ai-plugin.json\",\n",
        "    \"https://www.klarna.com/.well-known/ai-plugin.json\",\n",
        "    \"https://www.joinmilo.com/.well-known/ai-plugin.json\",\n",
        "    \"https://slack.com/.well-known/ai-plugin.json\",\n",
        "    \"https://schooldigger.com/.well-known/ai-plugin.json\",\n",
        "]\n",
        "\n",
        "AI_PLUGINS = [AIPlugin.from_url(url) for url in urls]"
      ],
      "metadata": {
        "id": "9Q42b5S7AhGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.schema import Document"
      ],
      "metadata": {
        "id": "bB367KC-Aiki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings()\n",
        "docs = [\n",
        "    Document(page_content=plugin.description_for_model, \n",
        "             metadata={\"plugin_name\": plugin.name_for_model}\n",
        "            )\n",
        "    for plugin in AI_PLUGINS\n",
        "]\n",
        "vector_store = FAISS.from_documents(docs, embeddings)\n",
        "toolkits_dict = {plugin.name_for_model: \n",
        "                 NLAToolkit.from_llm_and_ai_plugin(llm, plugin) \n",
        "                 for plugin in AI_PLUGINS}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSxfC3itAkMp",
        "outputId": "e56963ba-9479-44b9-e1d7-be73a03cf986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.tools.openapi.utils.openapi_utils:Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
            "WARNING:langchain.tools.openapi.utils.openapi_utils:Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
            "WARNING:langchain.tools.openapi.utils.openapi_utils:Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
            "WARNING:langchain.tools.openapi.utils.openapi_utils:Attempting to load an OpenAPI 3.0.2 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
            "WARNING:langchain.tools.openapi.utils.openapi_utils:Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
            "WARNING:langchain.tools.openapi.utils.openapi_utils:Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
            "WARNING:langchain.tools.openapi.utils.openapi_utils:Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
            "WARNING:langchain.tools.openapi.utils.openapi_utils:Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
            "WARNING:langchain.tools.openapi.utils.openapi_utils:Attempting to load a Swagger 2.0 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_store.as_retriever()\n",
        "\n",
        "def get_tools(query):\n",
        "    # Get documents, which contain the Plugins to use\n",
        "    docs = retriever.get_relevant_documents(query)\n",
        "    # Get the toolkits, one for each plugin\n",
        "    tool_kits = [toolkits_dict[d.metadata[\"plugin_name\"]] for d in docs]\n",
        "    # Get the tools: a separate NLAChain for each endpoint\n",
        "    tools = []\n",
        "    for tk in tool_kits:\n",
        "        tools.extend(tk.nla_tools)\n",
        "    return tools"
      ],
      "metadata": {
        "id": "Zyt3gjUzAljq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = get_tools(\"What could I do today with my kiddo\")\n",
        "[t.name for t in tools]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWatK08SAnJr",
        "outputId": "323d0073-ba00-4400-999e-963df4a09e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Milo.askMilo',\n",
              " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.search_all_actions',\n",
              " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.preview_a_zap',\n",
              " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.get_configuration_link',\n",
              " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.list_exposed_actions',\n",
              " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.get_execution_log_endpoint',\n",
              " 'SchoolDigger_API_V2.0.Autocomplete_GetSchools',\n",
              " 'SchoolDigger_API_V2.0.Districts_GetAllDistricts2',\n",
              " 'SchoolDigger_API_V2.0.Districts_GetDistrict2',\n",
              " 'SchoolDigger_API_V2.0.Rankings_GetSchoolRank2',\n",
              " 'SchoolDigger_API_V2.0.Rankings_GetRank_District',\n",
              " 'SchoolDigger_API_V2.0.Schools_GetAllSchools20',\n",
              " 'SchoolDigger_API_V2.0.Schools_GetSchool20',\n",
              " 'Speak.translate',\n",
              " 'Speak.explainPhrase',\n",
              " 'Speak.explainTask']"
            ]
          },
          "metadata": {},
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools = get_tools(\"what shirts can i buy?\")\n",
        "[t.name for t in tools]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzxqlqjZAoaG",
        "outputId": "7e73d204-9d7b-4224-e04a-b5713d0be19c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Open_AI_Klarna_product_Api.productsUsingGET',\n",
              " 'Milo.askMilo',\n",
              " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.search_all_actions',\n",
              " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.preview_a_zap',\n",
              " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.get_configuration_link',\n",
              " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.list_exposed_actions',\n",
              " 'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.get_execution_log_endpoint',\n",
              " 'SchoolDigger_API_V2.0.Autocomplete_GetSchools',\n",
              " 'SchoolDigger_API_V2.0.Districts_GetAllDistricts2',\n",
              " 'SchoolDigger_API_V2.0.Districts_GetDistrict2',\n",
              " 'SchoolDigger_API_V2.0.Rankings_GetSchoolRank2',\n",
              " 'SchoolDigger_API_V2.0.Rankings_GetRank_District',\n",
              " 'SchoolDigger_API_V2.0.Schools_GetAllSchools20',\n",
              " 'SchoolDigger_API_V2.0.Schools_GetSchool20']"
            ]
          },
          "metadata": {},
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the base template\n",
        "template = \"\"\"Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
        "\n",
        "{tools}\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "Question: the input question you must answer\n",
        "Thought: you should always think about what to do\n",
        "Action: the action to take, should be one of [{tool_names}]\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
        "\n",
        "Question: {input}\n",
        "{agent_scratchpad}\"\"\""
      ],
      "metadata": {
        "id": "rIEKZyr_AqOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable\n",
        "# Set up a prompt template\n",
        "class CustomPromptTemplate(StringPromptTemplate):\n",
        "    # The template to use\n",
        "    template: str\n",
        "    ############## NEW ######################\n",
        "    # The list of tools available\n",
        "    tools_getter: Callable\n",
        "    \n",
        "    def format(self, **kwargs) -> str:\n",
        "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
        "        # Format them in a particular way\n",
        "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
        "        thoughts = \"\"\n",
        "        for action, observation in intermediate_steps:\n",
        "            thoughts += action.log\n",
        "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
        "        # Set the agent_scratchpad variable to that value\n",
        "        kwargs[\"agent_scratchpad\"] = thoughts\n",
        "        ############## NEW ######################\n",
        "        tools = self.tools_getter(kwargs[\"input\"])\n",
        "        # Create a tools variable from the list of tools provided\n",
        "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in tools])\n",
        "        # Create a list of tool names for the tools provided\n",
        "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in tools])\n",
        "        return self.template.format(**kwargs)"
      ],
      "metadata": {
        "id": "CPWd1YHaArr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = CustomPromptTemplate(\n",
        "    template=template,\n",
        "    tools_getter=get_tools,\n",
        "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
        "    # This includes the `intermediate_steps` variable because that is needed\n",
        "    input_variables=[\"input\", \"intermediate_steps\"]\n",
        ")"
      ],
      "metadata": {
        "id": "hhUmgIRyAvhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomOutputParser(AgentOutputParser):\n",
        "    \n",
        "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
        "        # Check if agent should finish\n",
        "        if \"Final Answer:\" in llm_output:\n",
        "            return AgentFinish(\n",
        "                # Return values is generally always a dictionary with a single `output` key\n",
        "                # It is not recommended to try anything else at the moment :)\n",
        "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
        "                log=llm_output,\n",
        "            )\n",
        "        # Parse out the action and action input\n",
        "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
        "        match = re.search(regex, llm_output, re.DOTALL)\n",
        "        if not match:\n",
        "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
        "        action = match.group(1).strip()\n",
        "        action_input = match.group(2)\n",
        "        # Return the action and action input\n",
        "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)"
      ],
      "metadata": {
        "id": "VEBqcy2aAwvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser = CustomOutputParser()"
      ],
      "metadata": {
        "id": "rXL-ODucAyBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "# LLM chain consisting of the LLM and a prompt\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "tool_names = [tool.name for tool in tools]\n",
        "agent = LLMSingleActionAgent(\n",
        "    llm_chain=llm_chain, \n",
        "    output_parser=output_parser,\n",
        "    stop=[\"\\nObservation:\"], \n",
        "    allowed_tools=tool_names\n",
        ")"
      ],
      "metadata": {
        "id": "x9wwYCa2Azcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)\n",
        "agent_executor.run(\"what shirts can i buy?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "UPt4iYGLA3jJ",
        "outputId": "0c333964-f6c6-4084-fae7-31555dd0ff8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find a product API\n",
            "Action: Open_AI_Klarna_product_Api.productsUsingGET\n",
            "Action Input: shirts\u001b[0m\n",
            "\n",
            "Observation:\u001b[36;1m\u001b[1;3mI found several shirts in the API response. There are Burberry Check Poplin Shirt, Burberry Vintage Check Cotton Shirt - Beige, Burberry Vintage Check Stretch Cotton Twill Shirt, Magellan Outdoors Laguna Madre Solid Short Sleeve Fishing Shirt, Calvin Klein Slim Fit Oxford Dress Shirt, Cubavera Four Pocket Guayabera Shirt, Carhartt Loose Fit Midweight Chambray Short-Sleeve Shirt, Burberry Somerton Check Shirt - Camel, Van Heusen Men's Classic-Fit Wrinkle Free Flex Collar Stretch Solid Dress Shirt, and New Era NBA Script Mesh Tee Chicago Bulls. Prices range from $19.99 to $450.00.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: Arg, ye can buy a variety of shirts from Open AI Klarna product Api. Prices range from $19.99 to $450.00.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Arg, ye can buy a variety of shirts from Open AI Klarna product Api. Prices range from $19.99 to $450.00.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 개인비서 - LangChain에서 생성 에이전트\n",
        "\n",
        "이 노트북은 Park 등이 작성한 논문 Generative Agents: Interactive Simulacra of Human Behavior를 기반으로 하는 생성 에이전트를 구현합니다. 여기에서는 LangChain 검색기를 기반으로 한 시간 가중치가 있는 Memory 객체를 활용합니다."
      ],
      "metadata": {
        "id": "kc9ttW4iBGKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use termcolor to make it easy to colorize the outputs.\n",
        "!pip install termcolor > /dev/null"
      ],
      "metadata": {
        "id": "nLe-lcTZBCh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "from typing import List, Optional, Tuple\n",
        "from termcolor import colored\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from langchain import LLMChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.docstore import InMemoryDocstore\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
        "from langchain.schema import BaseLanguageModel, Document\n",
        "from langchain.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "azBcJP1oA6HE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USER_NAME = \"Person A\" # The name you want to use when interviewing the agent.\n",
        "LLM = ChatOpenAI(max_tokens=1500) # Can be any LLM you want."
      ],
      "metadata": {
        "id": "PLjVvX32BMBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "_parse_list: 줄바꿈 문자로 구분된 문자열을 리스트로 변환해주는 메서드입니다.\n",
        "\n",
        "_compute_agent_summary: 현재 Agent의 핵심 특성을 요약하여 반환하는 메서드입니다. 이 메서드는 '관련된 기억'을 얻어오고, 이를 LLMChain을 사용하여 요약 문자열을 생성합니다.\n",
        "\n",
        "_get_topics_of_reflection: 최근 관측에 대해 가장 중요한 세 가지 질문을 반환하는 메서드입니다. 이 메서드는 '관련된 기억'을 가져와 LLMChain을 사용하여 적절한 질문을 생성합니다.\n",
        "\n",
        "_get_insights_on_topic: LLMChain을 사용하여 지정된 주제에 대한 '인사이트'를 생성하는 메서드입니다.\n",
        "\n",
        "pause_to_reflect: 최근 관측에 대해 reflection_threshold로 지정된 값을 초과하면, 이 메서드를 호출하여 다시 생각하고 '인사이트'를 생성합니다.\n",
        "\n",
        "_score_memory_importance: 주어진 기억이 얼마나 중요한지 점수를 매겨 반환하는 메서드입니다.\n",
        "\n",
        "add_memory: 관찰 또는 기억을 Agent의 기억으로 추가하고, reflection_threshold에 도달하면 pause_to_reflect 메서드를 호출합니다.\n",
        "\n",
        "fetch_memories: 지정된 기억과 관련된 기억을 가져오는 메서드입니다.\n",
        "\n",
        "get_summary: Agent의 요약 문자열을 반환하는 메서드입니다.\n",
        "\n",
        "get_full_header: Agent의 요약 문자열, 상태 및 현재 시간을 포함한 전체 헤더 문자열을 반환하는 메서드입니다.\n",
        "\n",
        "_get_entity_from_observation: 관찰에 대한 관측체를 반환하는 메서드입니다.\n",
        "\n",
        "_get_entity_action: 관찰에 대한 관측체와 관련된 동작을 반환하는 메서드입니다.\n",
        "\n",
        "_format_memories_to_summarize: 요약할 관련 기억들의 형식을 변환하는 메서드입니다.\n",
        "\n",
        "summarize_related_memories: 관측과 관련된 가장 관련성 높은 기억들을 요약하여 반환하는 메서드입니다.\n",
        "\n",
        "_get_memories_until_limit: 최대 토큰 제한에 도달할 때까지 기억을 가져오는 메서드입니다.\n",
        "\n",
        "_generate_reaction: 관찰에 대한 응답 문자열을 생성하는 메서드입니다.\n",
        "\n",
        "generate_reaction: 관찰에 대한 응답을 생성하고, 'REACT' 또는 'SAY'를 반환합니다.\n",
        "\n",
        "generate_dialogue_response: 관찰에 대한 대화 응답을 생성하고, 'GOODBYE' 또는 'SAY'"
      ],
      "metadata": {
        "id": "X14W3kjywCsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GenerativeAgent(BaseModel):\n",
        "    \"\"\"A character with memory and innate characteristics.\"\"\"\n",
        "    \n",
        "    name: str\n",
        "    age: int\n",
        "    traits: str\n",
        "    \"\"\"The traits of the character you wish not to change.\"\"\"\n",
        "    status: str\n",
        "    \"\"\"Current activities of the character.\"\"\"\n",
        "    llm: BaseLanguageModel\n",
        "    memory_retriever: TimeWeightedVectorStoreRetriever\n",
        "    \"\"\"The retriever to fetch related memories.\"\"\"\n",
        "    verbose: bool = False\n",
        "    \n",
        "    reflection_threshold: Optional[float] = None\n",
        "    \"\"\"When the total 'importance' of memories exceeds the above threshold, stop to reflect.\"\"\"\n",
        "    \n",
        "    current_plan: List[str] = []\n",
        "    \"\"\"The current plan of the agent.\"\"\"\n",
        "    \n",
        "    summary: str = \"\"  #: :meta private:\n",
        "    summary_refresh_seconds: int= 3600  #: :meta private:\n",
        "    last_refreshed: datetime =Field(default_factory=datetime.now)  #: :meta private:\n",
        "    daily_summaries: List[str] #: :meta private:\n",
        "    memory_importance: float = 0.0 #: :meta private:\n",
        "    max_tokens_limit: int = 1200 #: :meta private:\n",
        "    \n",
        "    class Config:\n",
        "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
        "\n",
        "        arbitrary_types_allowed = True\n",
        "\n",
        "    @staticmethod\n",
        "    def _parse_list(text: str) -> List[str]:\n",
        "        \"\"\"Parse a newline-separated string into a list of strings.\"\"\"\n",
        "        lines = re.split(r'\\n', text.strip())\n",
        "        return [re.sub(r'^\\s*\\d+\\.\\s*', '', line).strip() for line in lines]\n",
        "\n",
        "    def _compute_agent_summary(self):\n",
        "        \"\"\"\"\"\"\n",
        "        prompt = PromptTemplate.from_template(\n",
        "            \"How would you summarize {name}'s core characteristics given the\"\n",
        "            +\" following statements:\\n\"\n",
        "            +\"{related_memories}\"\n",
        "            + \"Do not embellish.\"\n",
        "            +\"\\n\\nSummary: \"\n",
        "        )\n",
        "        # The agent seeks to think about their core characteristics.\n",
        "        relevant_memories = self.fetch_memories(f\"{self.name}'s core characteristics\")\n",
        "        relevant_memories_str = \"\\n\".join([f\"{mem.page_content}\" for mem in relevant_memories])\n",
        "        chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
        "        return chain.run(name=self.name, related_memories=relevant_memories_str).strip()\n",
        "    \n",
        "    def _get_topics_of_reflection(self, last_k: int = 50) -> Tuple[str, str, str]:\n",
        "        \"\"\"Return the 3 most salient high-level questions about recent observations.\"\"\"\n",
        "        prompt = PromptTemplate.from_template(\n",
        "            \"{observations}\\n\\n\"\n",
        "            + \"Given only the information above, what are the 3 most salient\"\n",
        "            + \" high-level questions we can answer about the subjects in the statements?\"\n",
        "            + \" Provide each question on a new line.\\n\\n\"\n",
        "        )\n",
        "        reflection_chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
        "        observations = self.memory_retriever.memory_stream[-last_k:]\n",
        "        observation_str = \"\\n\".join([o.page_content for o in observations])\n",
        "        result = reflection_chain.run(observations=observation_str)\n",
        "        return self._parse_list(result)\n",
        "    \n",
        "    def _get_insights_on_topic(self, topic: str) -> List[str]:\n",
        "        \"\"\"Generate 'insights' on a topic of reflection, based on pertinent memories.\"\"\"\n",
        "        prompt = PromptTemplate.from_template(\n",
        "            \"Statements about {topic}\\n\"\n",
        "            +\"{related_statements}\\n\\n\"\n",
        "            + \"What 5 high-level insights can you infer from the above statements?\"\n",
        "            + \" (example format: insight (because of 1, 5, 3))\"\n",
        "        )\n",
        "        related_memories = self.fetch_memories(topic)\n",
        "        related_statements = \"\\n\".join([f\"{i+1}. {memory.page_content}\" \n",
        "                                        for i, memory in \n",
        "                                        enumerate(related_memories)])\n",
        "        reflection_chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
        "        result = reflection_chain.run(topic=topic, related_statements=related_statements)\n",
        "        # TODO: Parse the connections between memories and insights\n",
        "        return self._parse_list(result)\n",
        "    \n",
        "    def pause_to_reflect(self) -> List[str]:\n",
        "        \"\"\"Reflect on recent observations and generate 'insights'.\"\"\"\n",
        "        print(colored(f\"Character {self.name} is reflecting\", \"blue\"))\n",
        "        new_insights = []\n",
        "        topics = self._get_topics_of_reflection()\n",
        "        for topic in topics:\n",
        "            insights = self._get_insights_on_topic( topic)\n",
        "            for insight in insights:\n",
        "                self.add_memory(insight)\n",
        "            new_insights.extend(insights)\n",
        "        return new_insights\n",
        "    \n",
        "    def _score_memory_importance(self, memory_content: str, weight: float = 0.15) -> float:\n",
        "        \"\"\"Score the absolute importance of the given memory.\"\"\"\n",
        "        # A weight of 0.25 makes this less important than it\n",
        "        # would be otherwise, relative to salience and time\n",
        "        prompt = PromptTemplate.from_template(\n",
        "         \"On the scale of 1 to 10, where 1 is purely mundane\"\n",
        "         +\" (e.g., brushing teeth, making bed) and 10 is\"\n",
        "         + \" extremely poignant (e.g., a break up, college\"\n",
        "         + \" acceptance), rate the likely poignancy of the\"\n",
        "         + \" following piece of memory. Respond with a single integer.\"\n",
        "         + \"\\nMemory: {memory_content}\"\n",
        "         + \"\\nRating: \"\n",
        "        )\n",
        "        chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
        "        score = chain.run(memory_content=memory_content).strip()\n",
        "        match = re.search(r\"^\\D*(\\d+)\", score)\n",
        "        if match:\n",
        "            return (float(score[0]) / 10) * weight\n",
        "        else:\n",
        "            return 0.0\n",
        "\n",
        "    def add_memory(self, memory_content: str) -> List[str]:\n",
        "        \"\"\"Add an observation or memory to the agent's memory.\"\"\"\n",
        "        importance_score = self._score_memory_importance(memory_content)\n",
        "        self.memory_importance += importance_score\n",
        "        document = Document(page_content=memory_content, metadata={\"importance\": importance_score})\n",
        "        result = self.memory_retriever.add_documents([document])\n",
        "\n",
        "        # After an agent has processed a certain amount of memories (as measured by\n",
        "        # aggregate importance), it is time to reflect on recent events to add\n",
        "        # more synthesized memories to the agent's memory stream.\n",
        "        if (self.reflection_threshold is not None \n",
        "            and self.memory_importance > self.reflection_threshold\n",
        "            and self.status != \"Reflecting\"):\n",
        "            old_status = self.status\n",
        "            self.status = \"Reflecting\"\n",
        "            self.pause_to_reflect()\n",
        "            # Hack to clear the importance from reflection\n",
        "            self.memory_importance = 0.0\n",
        "            self.status = old_status\n",
        "        return result\n",
        "    \n",
        "    def fetch_memories(self, observation: str) -> List[Document]:\n",
        "        \"\"\"Fetch related memories.\"\"\"\n",
        "        return self.memory_retriever.get_relevant_documents(observation)\n",
        "    \n",
        "    def get_summary(self, force_refresh: bool = False) -> str:\n",
        "        \"\"\"Return a descriptive summary of the agent.\"\"\"\n",
        "        current_time = datetime.now()\n",
        "        since_refresh = (current_time - self.last_refreshed).seconds\n",
        "        if not self.summary or since_refresh >= self.summary_refresh_seconds or force_refresh:\n",
        "            self.summary = self._compute_agent_summary()\n",
        "            self.last_refreshed = current_time\n",
        "        return (\n",
        "            f\"Name: {self.name} (age: {self.age})\"\n",
        "            +f\"\\nInnate traits: {self.traits}\"\n",
        "            +f\"\\n{self.summary}\"\n",
        "        )\n",
        "    \n",
        "    def get_full_header(self, force_refresh: bool = False) -> str:\n",
        "        \"\"\"Return a full header of the agent's status, summary, and current time.\"\"\"\n",
        "        summary = self.get_summary(force_refresh=force_refresh)\n",
        "        current_time_str =  datetime.now().strftime(\"%B %d, %Y, %I:%M %p\")\n",
        "        return f\"{summary}\\nIt is {current_time_str}.\\n{self.name}'s status: {self.status}\"\n",
        "    \n",
        "    def _get_entity_from_observation(self, observation: str) -> str:\n",
        "        prompt = PromptTemplate.from_template(\n",
        "            \"What is the observed entity in the following observation? {observation}\"\n",
        "            +\"\\nEntity=\"\n",
        "        )\n",
        "        chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
        "        return chain.run(observation=observation).strip()\n",
        "\n",
        "    def _get_entity_action(self, observation: str, entity_name: str) -> str:\n",
        "        prompt = PromptTemplate.from_template(\n",
        "            \"What is the {entity} doing in the following observation? {observation}\"\n",
        "            +\"\\nThe {entity} is\"\n",
        "        )\n",
        "        chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
        "        return chain.run(entity=entity_name, observation=observation).strip()\n",
        "    \n",
        "    def _format_memories_to_summarize(self, relevant_memories: List[Document]) -> str:\n",
        "        content_strs = set()\n",
        "        content = []\n",
        "        for mem in relevant_memories:\n",
        "            if mem.page_content in content_strs:\n",
        "                continue\n",
        "            content_strs.add(mem.page_content)\n",
        "            created_time = mem.metadata[\"created_at\"].strftime(\"%B %d, %Y, %I:%M %p\")\n",
        "            content.append(f\"- {created_time}: {mem.page_content.strip()}\")\n",
        "        return \"\\n\".join([f\"{mem}\" for mem in content])\n",
        "    \n",
        "    def summarize_related_memories(self, observation: str) -> str:\n",
        "        \"\"\"Summarize memories that are most relevant to an observation.\"\"\"\n",
        "        entity_name = self._get_entity_from_observation(observation)\n",
        "        entity_action = self._get_entity_action(observation, entity_name)\n",
        "        q1 = f\"What is the relationship between {self.name} and {entity_name}\"\n",
        "        relevant_memories = self.fetch_memories(q1) # Fetch memories related to the agent's relationship with the entity\n",
        "        q2 = f\"{entity_name} is {entity_action}\"\n",
        "        relevant_memories += self.fetch_memories(q2) # Fetch things related to the entity-action pair\n",
        "        context_str = self._format_memories_to_summarize(relevant_memories)\n",
        "        prompt = PromptTemplate.from_template(\n",
        "            \"{q1}?\\nContext from memory:\\n{context_str}\\nRelevant context: \"\n",
        "        )\n",
        "        chain = LLMChain(llm=self.llm, prompt=prompt, verbose=self.verbose)\n",
        "        return chain.run(q1=q1, context_str=context_str.strip()).strip()\n",
        "    \n",
        "    def _get_memories_until_limit(self, consumed_tokens: int) -> str:\n",
        "        \"\"\"Reduce the number of tokens in the documents.\"\"\"\n",
        "        result = []\n",
        "        for doc in self.memory_retriever.memory_stream[::-1]:\n",
        "            if consumed_tokens >= self.max_tokens_limit:\n",
        "                break\n",
        "            consumed_tokens += self.llm.get_num_tokens(doc.page_content)\n",
        "            if consumed_tokens < self.max_tokens_limit:\n",
        "                result.append(doc.page_content) \n",
        "        return \"; \".join(result[::-1])\n",
        "    \n",
        "    def _generate_reaction(\n",
        "        self,\n",
        "        observation: str,\n",
        "        suffix: str\n",
        "    ) -> str:\n",
        "        \"\"\"React to a given observation.\"\"\"\n",
        "        prompt = PromptTemplate.from_template(\n",
        "                \"{agent_summary_description}\"\n",
        "                +\"\\nIt is {current_time}.\"\n",
        "                +\"\\n{agent_name}'s status: {agent_status}\"\n",
        "                + \"\\nSummary of relevant context from {agent_name}'s memory:\"\n",
        "                +\"\\n{relevant_memories}\"\n",
        "                +\"\\nMost recent observations: {recent_observations}\"\n",
        "                + \"\\nObservation: {observation}\"\n",
        "                + \"\\n\\n\" + suffix\n",
        "        )\n",
        "        agent_summary_description = self.get_summary()\n",
        "        relevant_memories_str = self.summarize_related_memories(observation)\n",
        "        current_time_str = datetime.now().strftime(\"%B %d, %Y, %I:%M %p\")\n",
        "        kwargs = dict(agent_summary_description=agent_summary_description,\n",
        "                      current_time=current_time_str,\n",
        "                      relevant_memories=relevant_memories_str,\n",
        "                      agent_name=self.name,\n",
        "                      observation=observation,\n",
        "                     agent_status=self.status)\n",
        "        consumed_tokens = self.llm.get_num_tokens(prompt.format(recent_observations=\"\", **kwargs))\n",
        "        kwargs[\"recent_observations\"] = self._get_memories_until_limit(consumed_tokens)\n",
        "        action_prediction_chain = LLMChain(llm=self.llm, prompt=prompt)\n",
        "        result = action_prediction_chain.run(**kwargs)\n",
        "        return result.strip()\n",
        "    \n",
        "    def generate_reaction(self, observation: str) -> Tuple[bool, str]:\n",
        "        \"\"\"React to a given observation.\"\"\"\n",
        "        call_to_action_template = (\n",
        "            \"Should {agent_name} react to the observation, and if so,\"\n",
        "            +\" what would be an appropriate reaction? Respond in one line.\"\n",
        "            +' If the action is to engage in dialogue, write:\\nSAY: \"what to say\"'\n",
        "            +\"\\notherwise, write:\\nREACT: {agent_name}'s reaction (if anything).\"\n",
        "            + \"\\nEither do nothing, react, or say something but not both.\\n\\n\"\n",
        "        )\n",
        "        full_result = self._generate_reaction(observation, call_to_action_template)\n",
        "        result = full_result.strip().split('\\n')[0]\n",
        "        self.add_memory(f\"{self.name} observed {observation} and reacted by {result}\")\n",
        "        if \"REACT:\" in result:\n",
        "            reaction = result.split(\"REACT:\")[-1].strip()\n",
        "            return False, f\"{self.name} {reaction}\"\n",
        "        if \"SAY:\" in result:\n",
        "            said_value = result.split(\"SAY:\")[-1].strip()\n",
        "            return True, f\"{self.name} said {said_value}\"\n",
        "        else:\n",
        "            return False, result\n",
        "\n",
        "    def generate_dialogue_response(self, observation: str) -> Tuple[bool, str]:\n",
        "        \"\"\"React to a given observation.\"\"\"\n",
        "        call_to_action_template = (\n",
        "            'What would {agent_name} say? To end the conversation, write: GOODBYE: \"what to say\". Otherwise to continue the conversation, write: SAY: \"what to say next\"\\n\\n'\n",
        "        )\n",
        "        full_result = self._generate_reaction(observation, call_to_action_template)\n",
        "        result = full_result.strip().split('\\n')[0]\n",
        "        if \"GOODBYE:\" in result:\n",
        "            farewell = result.split(\"GOODBYE:\")[-1].strip()\n",
        "            self.add_memory(f\"{self.name} observed {observation} and said {farewell}\")\n",
        "            return False, f\"{self.name} said {farewell}\"\n",
        "        if \"SAY:\" in result:\n",
        "            response_text = result.split(\"SAY:\")[-1].strip()\n",
        "            self.add_memory(f\"{self.name} observed {observation} and said {response_text}\")\n",
        "            return True, f\"{self.name} said {response_text}\"\n",
        "        else:\n",
        "            return False, result"
      ],
      "metadata": {
        "id": "HpaN4Gc9BNc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import faiss\n",
        "\n",
        "def relevance_score_fn(score: float) -> float:\n",
        "    \"\"\"Return a similarity score on a scale [0, 1].\"\"\"\n",
        "    # This will differ depending on a few things:\n",
        "    # - the distance / similarity metric used by the VectorStore\n",
        "    # - the scale of your embeddings (OpenAI's are unit norm. Many others are not!)\n",
        "    # This function converts the euclidean norm of normalized embeddings\n",
        "    # (0 is most similar, sqrt(2) most dissimilar)\n",
        "    # to a similarity function (0 to 1)\n",
        "    return 1.0 - score / math.sqrt(2)\n",
        "\n",
        "def create_new_memory_retriever():\n",
        "    \"\"\"Create a new vector store retriever unique to the agent.\"\"\"\n",
        "    # Define your embedding model\n",
        "    embeddings_model = OpenAIEmbeddings()\n",
        "    # Initialize the vectorstore as empty\n",
        "    embedding_size = 1536\n",
        "    index = faiss.IndexFlatL2(embedding_size)\n",
        "    vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {}, relevance_score_fn=relevance_score_fn)\n",
        "    return TimeWeightedVectorStoreRetriever(vectorstore=vectorstore, other_score_keys=[\"importance\"], k=15)    "
      ],
      "metadata": {
        "id": "yb0HidADBUDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tommie = GenerativeAgent(name=\"Tommie\", \n",
        "              age=25,\n",
        "              traits=\"anxious, likes design\", # You can add more persistent traits here \n",
        "              status=\"looking for a job\", # When connected to a virtual world, we can have the characters update their status\n",
        "              memory_retriever=create_new_memory_retriever(),\n",
        "              llm=LLM,\n",
        "              daily_summaries = [\n",
        "                   \"Drove across state to move to a new town but doesn't have a job yet.\"\n",
        "               ],\n",
        "               reflection_threshold = 8, # we will give this a relatively low number to show how reflection works\n",
        "             )"
      ],
      "metadata": {
        "id": "gmMKbpRRBbF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The current \"Summary\" of a character can't be made because the agent hasn't made\n",
        "# any observations yet.\n",
        "print(tommie.get_summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmAL_4zaBccz",
        "outputId": "c1e5bd79-002c-46e2-d326-fd5facc78406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Tommie (age: 25)\n",
            "Innate traits: anxious, likes design\n",
            "Unknown, as no statements are provided.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can give the character memories directly\n",
        "tommie_memories = [\n",
        "    \"Tommie remembers his dog, Bruno, from when he was a kid\",\n",
        "    \"Tommie feels tired from driving so far\",\n",
        "    \"Tommie sees the new home\",\n",
        "    \"The new neighbors have a cat\",\n",
        "    \"The road is noisy at night\",\n",
        "    \"Tommie is hungry\",\n",
        "    \"Tommie tries to get some rest.\",\n",
        "]\n",
        "for memory in tommie_memories:\n",
        "    tommie.add_memory(memory)"
      ],
      "metadata": {
        "id": "wcRkJNmpBd7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now that Tommie has 'memories', their self-summary is more descriptive, though still rudimentary.\n",
        "# We will see how this summary updates after more observations to create a more rich description.\n",
        "print(tommie.get_summary(force_refresh=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyKAV_r5Bfee",
        "outputId": "5efb4e30-f303-4a55-b74f-258ec5827153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Tommie (age: 25)\n",
            "Innate traits: anxious, likes design\n",
            "Tommie is observant, has a strong memory, experiences basic human needs such as hunger and rest, and is affected by external factors such as noise.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def interview_agent(agent: GenerativeAgent, message: str) -> str:\n",
        "    \"\"\"Help the notebook user interact with the agent.\"\"\"\n",
        "    new_message = f\"{USER_NAME} says {message}\"\n",
        "    return agent.generate_dialogue_response(new_message)[1]"
      ],
      "metadata": {
        "id": "jDt30LGJBhSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interview_agent(tommie, \"What do you like to do?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "D70k15iiBjaz",
        "outputId": "eea64549-97ba-4f8d-dd91-5561aea46750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tommie said \"I really enjoy design, I find it relaxing and fulfilling. I\\'ve been practicing my skills in graphic design and interior design in my free time, and I\\'m looking for a job in those fields.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interview_agent(tommie, \"What are you looking forward to doing today?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ocw1XpMTBkwo",
        "outputId": "6e5336b4-aebc-4d01-c6a0-ed8a1240216e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tommie said \"I\\'m actually looking for a job today. Hoping to find something in the design field.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interview_agent(tommie, \"What are you most worried about today?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "pVqdcKP5BnPJ",
        "outputId": "207a4463-bda7-4afa-c71e-daa0ed9ee237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tommie said \"Honestly, I\\'m feeling quite anxious about finding a job. I\\'ve been searching for a while and it\\'s been a bit discouraging. But I\\'m trying to stay positive and keep pushing forward.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's have Tommie start going through a day in the life.\n",
        "observations = [\n",
        "    \"Tommie wakes up to the sound of a noisy construction site outside his window.\",\n",
        "    \"Tommie gets out of bed and heads to the kitchen to make himself some coffee.\",\n",
        "    \"Tommie realizes he forgot to buy coffee filters and starts rummaging through his moving boxes to find some.\",\n",
        "    \"Tommie finally finds the filters and makes himself a cup of coffee.\",\n",
        "    \"The coffee tastes bitter, and Tommie regrets not buying a better brand.\",\n",
        "    \"Tommie checks his email and sees that he has no job offers yet.\",\n",
        "    \"Tommie spends some time updating his resume and cover letter.\",\n",
        "    \"Tommie heads out to explore the city and look for job openings.\",\n",
        "    \"Tommie sees a sign for a job fair and decides to attend.\",\n",
        "    \"The line to get in is long, and Tommie has to wait for an hour.\",\n",
        "    \"Tommie meets several potential employers at the job fair but doesn't receive any offers.\",\n",
        "    \"Tommie leaves the job fair feeling disappointed.\",\n",
        "    \"Tommie stops by a local diner to grab some lunch.\",\n",
        "    \"The service is slow, and Tommie has to wait for 30 minutes to get his food.\",\n",
        "    \"Tommie overhears a conversation at the next table about a job opening.\",\n",
        "    \"Tommie asks the diners about the job opening and gets some information about the company.\",\n",
        "    \"Tommie decides to apply for the job and sends his resume and cover letter.\",\n",
        "    \"Tommie continues his search for job openings and drops off his resume at several local businesses.\",\n",
        "    \"Tommie takes a break from his job search to go for a walk in a nearby park.\",\n",
        "    \"A dog approaches and licks Tommie's feet, and he pets it for a few minutes.\",\n",
        "    \"Tommie sees a group of people playing frisbee and decides to join in.\",\n",
        "    \"Tommie has fun playing frisbee but gets hit in the face with the frisbee and hurts his nose.\",\n",
        "    \"Tommie goes back to his apartment to rest for a bit.\",\n",
        "    \"A raccoon tore open the trash bag outside his apartment, and the garbage is all over the floor.\",\n",
        "    \"Tommie starts to feel frustrated with his job search.\",\n",
        "    \"Tommie calls his best friend to vent about his struggles.\",\n",
        "    \"Tommie's friend offers some words of encouragement and tells him to keep trying.\",\n",
        "    \"Tommie feels slightly better after talking to his friend.\",\n",
        "]"
      ],
      "metadata": {
        "id": "yWt00fljBq1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's send Tommie on their way. We'll check in on their summary every few observations to watch it evolve\n",
        "for i, observation in enumerate(observations):\n",
        "    _, reaction = tommie.generate_reaction(observation)\n",
        "    print(colored(observation, \"green\"), reaction)\n",
        "    if ((i+1) % 20) == 0:\n",
        "        print('*'*40)\n",
        "        print(colored(f\"After {i+1} observations, Tommie's summary is:\\n{tommie.get_summary(force_refresh=True)}\", \"blue\"))\n",
        "        print('*'*40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyiLtajFBtRo",
        "outputId": "d91a3d76-50a1-4705-9443-038c6f8e87ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tommie wakes up to the sound of a noisy construction site outside his window. Tommie Tommie groans and tries to cover his head with a pillow to block out the noise.\n",
            "Tommie gets out of bed and heads to the kitchen to make himself some coffee. Tommie Tommie starts making coffee.\n",
            "Tommie realizes he forgot to buy coffee filters and starts rummaging through his moving boxes to find some. Tommie Tommie sighs in frustration and continues searching through the boxes for the coffee filters.\n",
            "Tommie finally finds the filters and makes himself a cup of coffee. Tommie Tommie takes a sip of his coffee and feels a sense of relief.\n",
            "The coffee tastes bitter, and Tommie regrets not buying a better brand. Tommie Tommie grimaces at the taste of the coffee and makes a mental note to buy a better brand next time.\n",
            "Tommie checks his email and sees that he has no job offers yet. Tommie Tommie feels disappointed but tries to stay positive and continue the job search.\n",
            "Tommie spends some time updating his resume and cover letter. Tommie Tommie nods with satisfaction, feeling accomplished for updating his resume and cover letter.\n",
            "Tommie heads out to explore the city and look for job openings. Tommie Tommie feels determined to find a job and starts walking around the city.\n",
            "Tommie sees a sign for a job fair and decides to attend. Tommie Tommie's eyes light up with hope and he quickens his pace towards the job fair.\n",
            "The line to get in is long, and Tommie has to wait for an hour. Tommie Tommie sighs and checks the time, feeling impatient.\n",
            "Tommie meets several potential employers at the job fair but doesn't receive any offers. Tommie Tommie feels discouraged but tries to stay positive and continues the job search.\n",
            "Tommie leaves the job fair feeling disappointed. Tommie Tommie's mood becomes downcast as he reflects on not receiving any job offers.\n",
            "Tommie stops by a local diner to grab some lunch. Tommie Tommie's stomach grumbles with anticipation as he enters the diner.\n",
            "The service is slow, and Tommie has to wait for 30 minutes to get his food. Tommie Tommie patiently waits for his food, feeling hungry but understanding that the service may be busy.\n",
            "Tommie overhears a conversation at the next table about a job opening. Tommie said \"Excuse me, I couldn't help but overhear about the job opening. Can you tell me more about it?\"\n",
            "Tommie asks the diners about the job opening and gets some information about the company. Tommie said \"Thank you for the information, I'll definitely check it out.\"\n",
            "Tommie decides to apply for the job and sends his resume and cover letter. Tommie said \"Thank you for the information, I'll definitely check it out.\"\n",
            "Tommie continues his search for job openings and drops off his resume at several local businesses. Tommie Tommie nods with determination and continues his search for job openings.\n",
            "Tommie takes a break from his job search to go for a walk in a nearby park. Tommie Tommie takes a deep breath and enjoys the fresh air in the park.\n",
            "A dog approaches and licks Tommie's feet, and he pets it for a few minutes. Tommie Tommie smiles and continues to pet the dog for a few more minutes.\n",
            "****************************************\n",
            "After 20 observations, Tommie's summary is:\n",
            "Name: Tommie (age: 25)\n",
            "Innate traits: anxious, likes design\n",
            "Tommie is determined and persistent in his job search, even when faced with disappointment. He tries to stay positive and takes breaks when needed. He values his accomplishments and enjoys simple pleasures like spending time with a dog or drinking coffee. Tommie also has a strong sense of hope and is willing to take action to achieve his goals.\n",
            "****************************************\n",
            "Tommie sees a group of people playing frisbee and decides to join in. Tommie said \"Can I join in the game?\"\n",
            "Tommie has fun playing frisbee but gets hit in the face with the frisbee and hurts his nose. Tommie Tommie winces in pain and touches his nose, but tries to laugh it off and continues playing.\n",
            "Tommie goes back to his apartment to rest for a bit. Tommie Tommie sits down on his couch and takes a deep breath, feeling tired from the day's events.\n",
            "A raccoon tore open the trash bag outside his apartment, and the garbage is all over the floor. Tommie Tommie sighs and heads outside to clean up the garbage.\n",
            "Tommie starts to feel frustrated with his job search. Tommie Tommie takes a deep breath and tries to remain calm, reminding himself of his determination to find a job.\n",
            "Tommie calls his best friend to vent about his struggles. Tommie said \"Hey, can we talk? I need to vent about my job search.\"\n",
            "Tommie's friend offers some words of encouragement and tells him to keep trying. Tommie said \"Thank you for the encouragement, it means a lot.\"\n",
            "Tommie feels slightly better after talking to his friend. Tommie said \"Thank you for being there for me, it really helps to talk to someone about my job search.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interview_agent(tommie, \"Tell me about how your day has been going\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "67x7ze9bBvAY",
        "outputId": "4b2797a2-9b75-48d3-e3e6-214d8623e89a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tommie said \"Well, it\\'s been a bit of a mixed day. I went to a job fair but didn\\'t get any offers, but then I found out about a potential job opening at a diner and applied for it. I also had some fun playing frisbee in the park, but then I got hit in the face with the frisbee and hurt my nose. Overall, it\\'s been a bit of a rollercoaster, but I\\'m still determined to find a job.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interview_agent(tommie, \"How do you feel about coffee?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rb2UTS6tByfM",
        "outputId": "da25e0e1-5091-461d-f492-5f9ee4cbbe4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tommie said \"Well, I really enjoy coffee. It\\'s a small comfort in my day and helps me stay energized. I\\'m pretty particular about the taste and quality though. How about you, do you like coffee?\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interview_agent(tommie, \"Tell me about your childhood dog!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "grO7rNz9Bz_C",
        "outputId": "9ec0403e-c576-4238-eec8-3eb19a89a28d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tommie said \"Oh, I had a dog growing up named Bruno. He was a really sweet and loyal companion. I miss him a lot. How about you, did you have any pets growing up?\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eve = GenerativeAgent(name=\"Eve\", \n",
        "              age=34, \n",
        "              traits=\"curious, helpful\", # You can add more persistent traits here \n",
        "              status=\"N/A\", # When connected to a virtual world, we can have the characters update their status\n",
        "              memory_retriever=create_new_memory_retriever(),\n",
        "              llm=LLM,\n",
        "              daily_summaries = [\n",
        "                  (\"Eve started her new job as a career counselor last week and received her first assignment, a client named Tommie.\")\n",
        "              ],\n",
        "                reflection_threshold = 5,\n",
        "             )"
      ],
      "metadata": {
        "id": "0WbHegeSB3Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yesterday = (datetime.now() - timedelta(days=1)).strftime(\"%A %B %d\")\n",
        "eve_memories = [\n",
        "    \"Eve overhears her colleague say something about a new client being hard to work with\",\n",
        "    \"Eve wakes up and hear's the alarm\",\n",
        "    \"Eve eats a boal of porridge\",\n",
        "    \"Eve helps a coworker on a task\",\n",
        "    \"Eve plays tennis with her friend Xu before going to work\",\n",
        "    \"Eve overhears her colleague say something about Tommie being hard to work with\",\n",
        "    \n",
        "]\n",
        "for memory in eve_memories:\n",
        "    eve.add_memory(memory)"
      ],
      "metadata": {
        "id": "sJXbzKxaB5In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(eve.get_summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-84gOllB7oo",
        "outputId": "9318492e-ae4e-4ae3-98c4-d56bc6b0910f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Eve (age: 34)\n",
            "Innate traits: curious, helpful\n",
            "Eve is helpful, active, eats breakfast, attentive, and wakes up on time.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interview_agent(eve, \"How are you feeling about today?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dricws0CB9bH",
        "outputId": "f24d6fb2-1755-4a90-87d3-1846e5430293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Eve said \"I\\'m feeling pretty good today, thanks for asking. How about you?\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interview_agent(eve, \"What do you know about Tommie?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "VAnoSaEZB-z_",
        "outputId": "dcd6f89b-bb66-4b4d-b584-5c197123a55d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Eve said \"What do you mean? I\\'m not sure who Tommie is.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interview_agent(eve, \"Tommie is looking to find a job. What are are some things you'd like to ask him?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jVomTjQFCAMP",
        "outputId": "c9ec77f3-7f25-4e55-f91f-b3e772600094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Eve said \"That\\'s great to hear. What kind of job is Tommie looking for?\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interview_agent(eve, \"Tommie is looking to find a job. What are are some things you'd like to ask him?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AonGq54hCBuM",
        "outputId": "d813b830-1139-4501-b8ed-4ffa59948558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Eve said \"That\\'s great to hear. What kind of job is Tommie looking for?\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interview_agent(eve, \"You'll have to ask him. He may be a bit anxious, so I'd appreciate it if you keep the conversation going and ask as many questions as possible.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "AhlktIj9CC92",
        "outputId": "2fddd11e-8cd5-4227-ce43-609463fd4f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Eve said \"Sure, I\\'d be happy to talk to Tommie and ask him some questions. What kind of industry or field does he have experience in?\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_conversation(agents: List[GenerativeAgent], initial_observation: str) -> None:\n",
        "    \"\"\"Runs a conversation between agents.\"\"\"\n",
        "    _, observation = agents[1].generate_reaction(initial_observation)\n",
        "    print(observation)\n",
        "    turns = 0\n",
        "    while True:\n",
        "        break_dialogue = False\n",
        "        for agent in agents:\n",
        "            stay_in_dialogue, observation = agent.generate_dialogue_response(observation)\n",
        "            print(observation)\n",
        "            # observation = f\"{agent.name} said {reaction}\"\n",
        "            if not stay_in_dialogue:\n",
        "                break_dialogue = True   \n",
        "        if break_dialogue:\n",
        "            break\n",
        "        turns += 1"
      ],
      "metadata": {
        "id": "RtcC1KFWCEeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agents = [tommie, eve]\n",
        "run_conversation(agents, \"Tommie said: Hi, Eve. Thanks for agreeing to share your story with me and give me advice. I have a bunch of questions.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywUEBLdZCGFU",
        "outputId": "4e4bce7f-3595-496c-c861-98de4b81759a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eve said \"Of course, Tommie. I'm happy to help. What questions do you have?\"\n",
            "Tommie said \"Thank you so much, Eve. I really appreciate your willingness to help. Can you tell me more about your experience with job searching?\"\n",
            "Eve said \"Of course, Tommie. I've had experience job searching both before and during my current position. What specific questions do you have?\"\n",
            "Tommie said \"Thank you so much for your help, Eve. I really appreciate it. Have a great day!\"\n",
            "Eve said \"You're welcome, Tommie. It was my pleasure to help. Have a great day!\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can see a current \"Summary\" of a character based on their own perception of self\n",
        "# has changed\n",
        "print(tommie.get_summary(force_refresh=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSpIhGLHCH6P",
        "outputId": "2daa23fa-2bd7-46b8-a4a3-92aceca2b2ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Tommie (age: 25)\n",
            "Innate traits: anxious, likes design\n",
            "Tommie is determined and persistent in his job search, even when faced with disappointment and frustration. He tries to stay positive and seeks support from friends when needed. He also enjoys taking breaks and having fun, but is able to handle setbacks with resilience. He has a strong connection to his childhood dog, Bruno.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(eve.get_summary(force_refresh=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-7GPZYrCJYj",
        "outputId": "544a7f37-35f3-466b-96c5-4305a8919f87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Eve (age: 34)\n",
            "Innate traits: curious, helpful\n",
            "Eve is helpful, active, observant, and communicative. She shows empathy towards her colleague and friend, and is willing to offer advice and assistance. She pays attention to her surroundings and is curious about others. She is also polite and courteous in her interactions with others.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interview_agent(tommie, \"How was your conversation with Eve?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "wGaLvsV-CK8t",
        "outputId": "243ad408-51b9-4bc4-c401-d19ef76cf943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tommie said \"It went really well, actually. Eve was very helpful and gave me some good advice. I\\'m feeling more hopeful about my job search now. How about you, have you had any luck with job searching?\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interview_agent(eve, \"How was your conversation with Tommie?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "O0lwCe3nCMN0",
        "outputId": "59729896-2120-4236-9334-813c3fb4bd7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Eve said \"It was great, thanks for asking. Tommie had some good questions about job searching and I was happy to provide some advice. How about you, have you worked with Tommie before?\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interview_agent(eve, \"What do you wish you would have said to Tommie?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "goZsNWIVCN0r",
        "outputId": "338bcbb4-321b-4526-fd1c-ced62f328a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Eve said \"Well, I feel like I covered a lot of ground with Tommie and answered his questions thoroughly. I\\'m not sure if there\\'s anything else specific he was looking for, but I\\'m happy to follow up with him if he has more questions. Did you have any suggestions for what I could have said to him?\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interview_agent(tommie, \"What happened with your coffee this morning?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "qD2IxeglCPUL",
        "outputId": "c10eebbb-3322-4a2f-a984-9593177c8de6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tommie said \"Oh, I regret not buying a better brand because it tasted bitter. But it\\'s okay, I\\'ll try again tomorrow. How about you, do you have a favorite brand of coffee?\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 281
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 문서 QA\n"
      ],
      "metadata": {
        "id": "2BwYPnIFCd6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "zA0rkrZACmXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PDF 파일 경로 목록\n",
        "pdf_files = [\n",
        "    \"docs/AF_회사소개서.pdf\",\n",
        "    \"docs/AF_러닝데이_overview.pdf\",\n",
        "    \"docs/인공지능팩토리_개발용역_실적_요약서.pdf\"\n",
        "]\n",
        "\n",
        "# 로더, 텍스트 분할기 및 임베딩 초기화\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "texts = []\n",
        "\n",
        "# 각 PDF 파일에 대해 작업 수행\n",
        "for pdf_file in pdf_files:\n",
        "    loader = PyPDFLoader(pdf_file)\n",
        "    documents = loader.load()\n",
        "    texts.extend(text_splitter.split_documents(documents))\n",
        "\n",
        "docsearch = Chroma.from_documents(texts, embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDhtlcVjLnXz",
        "outputId": "214dbfed-bb05-4177-ccc0-628e2b554cc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb:Using embedded DuckDB without persistence: data will be transient\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Answer in Korean:\"\"\"\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")"
      ],
      "metadata": {
        "id": "7DJQa9hDEjgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_type_kwargs = {\"prompt\": PROMPT}\n",
        "qa = RetrievalQA.from_chain_type(llm=OpenAI(), \n",
        "                                 chain_type=\"stuff\", \n",
        "                                 retriever=docsearch.as_retriever(), \n",
        "                                 return_source_documents=True, \n",
        "                                 chain_type_kwargs=chain_type_kwargs)"
      ],
      "metadata": {
        "id": "QGrXF7HzLLfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"인공지능팩토리는 무엇을 하는 회사인가?\"\n",
        "result = qa({\"query\": query})"
      ],
      "metadata": {
        "id": "K4SEOcngLMyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"result\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wQ0TugaeYrRb",
        "outputId": "5fcf4355-740a-431d-e853-db32e92b5c35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 인공지능팩토리는 END-TO-END 서비스를 제공하는 토탈 AI 플랫폼 서비스를 제공하는 회사입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"source_documents\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6O6LZpJYu5v",
        "outputId": "c9fbb094-224b-4721-898c-1b333ed6f6cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Company Profile\\n인공지능팩토리회사소개서', metadata={'source': 'docs/AF_회사소개서.pdf', 'page': 0}),\n",
              " Document(page_content='인공지능팩토리는토탈AI\\x00플랫폼서비스입니다.AI 컨설팅부터AI 모델개발, 평가검증및유지보수관리에이르기까지END-TO-END 서비스를제공하며,인공지능경진대회플랫폼및교육실습플랫폼을발판으로AI 생태계를조성하고활성화시키고자합니다.40+경진대회90+태스크10K+보유회원30+고객사\\n0120.01~02-법인설립-기업부설연구소인증20.07~08-초기창업패키지선정-시드투자유치20.11-IITP 인공지능그랜드챌린지-NIPA 인공지능문제해결경진대회21.09~1122.0322.09*2022년4월기준\\n-창업진흥원2021 AI챔피언십-연구개발특구진흥재단경진대회-NIA 서비스공모전경진대회-Microsoft 애저톤경진대회-ETRI휴먼이해인공지능경진대회-KT-ETRI네트워크지능화를위한인공지능경진대회-농림수산식품교육문화정보원실증재배경진대회-한국가스공사주최경진대회운영', metadata={'source': 'docs/AF_회사소개서.pdf', 'page': 1}),\n",
              " Document(page_content='05WHY AI FACTORY?전문성있는AI 컨설팅AI기술을도입하고싶지만, 어디부터어떻게적용해야할지막막한분들께인공지능팩토리는최고의파트너입니다. 업계전문가의수준높은컨설팅을통해, 문제정의부터최적화관리까지진정한의미의토탈솔루션을제공합니다.독보적인인공지능모델& 데이터평가검증역량인공지능팩토리는창업이후1년만에20개이상의고객사와함께경진대회개최및모델을개발검증해왔습니다. 다양한산업군경험과전문가기반의평가검증역량으로믿을수있는결과물을드립니다.마무리까지확실한유지보수관리인공지능팩토리는신뢰를중요시합니다. 단순히결과물을전달하는데서끝나지않고사후관리까지담당하여최적화된상태로인공지능모델이이용되도록합니다.', metadata={'source': 'docs/AF_회사소개서.pdf', 'page': 5}),\n",
              " Document(page_content='다가올미래사회에서의인공지능의역할은더중요해질것으로예상되고있으며, 따라서인공지능모델개발수요역시급증할것으로기대되고있습니다. 그러나인공지능모델개발에성공했다고하더라도실제인공지능모델을운영하기위해서는다양하게고려해야할사항들이많습니다.\\n04ProblemSolution\\n인공지능팩토리는즉시성, 공유성, 실시간성, 상호작용성및집단지성등의특징을가지고있는토탈AI 플랫폼을제공하여,AI 기술을원하는분들이언제어디서든손쉽게인공지능서비스를이용할수있도록지원합니다.인공지능모델운영을위한다양한고려요소들인공지능을위한플랫폼토탈솔루션', metadata={'source': 'docs/AF_회사소개서.pdf', 'page': 4})]"
            ]
          },
          "metadata": {},
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"인공지능팩토리가 수행한 이미지 분석 관련 프로젝트는?\"\n",
        "result = qa({\"query\": query})"
      ],
      "metadata": {
        "id": "yu6a0bywWaT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"result\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0SzVV4_YY377",
        "outputId": "00227bda-035b-4f43-ee2a-cdf09cfb96f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 과제명 2020년 미디어 플랫폼 AI 관제시스템 개발'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"source_documents\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZkonfFGY4ZB",
        "outputId": "06eccecc-1828-4556-8a4f-a82911eb4d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Company Profile\\n인공지능팩토리회사소개서', metadata={'source': 'docs/AF_회사소개서.pdf', 'page': 0}),\n",
              " Document(page_content='인공지능팩토리는토탈AI\\x00플랫폼서비스입니다.AI 컨설팅부터AI 모델개발, 평가검증및유지보수관리에이르기까지END-TO-END 서비스를제공하며,인공지능경진대회플랫폼및교육실습플랫폼을발판으로AI 생태계를조성하고활성화시키고자합니다.40+경진대회90+태스크10K+보유회원30+고객사\\n0120.01~02-법인설립-기업부설연구소인증20.07~08-초기창업패키지선정-시드투자유치20.11-IITP 인공지능그랜드챌린지-NIPA 인공지능문제해결경진대회21.09~1122.0322.09*2022년4월기준\\n-창업진흥원2021 AI챔피언십-연구개발특구진흥재단경진대회-NIA 서비스공모전경진대회-Microsoft 애저톤경진대회-ETRI휴먼이해인공지능경진대회-KT-ETRI네트워크지능화를위한인공지능경진대회-농림수산식품교육문화정보원실증재배경진대회-한국가스공사주최경진대회운영', metadata={'source': 'docs/AF_회사소개서.pdf', 'page': 1}),\n",
              " Document(page_content='사업명 -\\n과제명 2020년미디어플랫폼 AI 관제시스템개발\\n발주기관 KT주관기관 ㈜인공지능팩토리\\n공동개발기관 ㈜제로원에이아이\\n사업기간❖[1차] 2020년01월28일~ 2020년06월30일\\n❖[2차] 2020년08월19일~ 2021년02월12일\\n사업목표❖AI 기반장애예측을통한선제적예방및신속한인조/조치체계구축\\n❖자율형네트워크별 데이터및AI 모델버전관리체계구축\\n사업내용❖신속한장애판단및예측으로 대형고장 예방및운용생산성향상\\n❖대형고장 선제적대응필요및감시체계정교화를 위한딥러닝기반의미디어\\nAI 관제시스템개발\\n➢다양한서비스를 보유하고 있는고객사를 위해실시간으로 시계열로그이\\n상징후를 감지할수있는알고리즘 개발및운영을위한플랫폼을 제공함 .\\n➢이전에는 사람이직접개입했던 모니터링 시스템을 딥러닝기반의시스템\\n을통해신속한장애판단 및예측으로 대형고장예측및운용생산성을 향\\n상시킴 .\\n< 로그인화면 >\\n< 소프트웨어 구성도 >\\n< 하드웨어 구성도 >\\n< 메인화면 >', metadata={'source': 'docs/인공지능팩토리_개발용역_실적_요약서.pdf', 'page': 3}),\n",
              " Document(page_content='다가올미래사회에서의인공지능의역할은더중요해질것으로예상되고있으며, 따라서인공지능모델개발수요역시급증할것으로기대되고있습니다. 그러나인공지능모델개발에성공했다고하더라도실제인공지능모델을운영하기위해서는다양하게고려해야할사항들이많습니다.\\n04ProblemSolution\\n인공지능팩토리는즉시성, 공유성, 실시간성, 상호작용성및집단지성등의특징을가지고있는토탈AI 플랫폼을제공하여,AI 기술을원하는분들이언제어디서든손쉽게인공지능서비스를이용할수있도록지원합니다.인공지능모델운영을위한다양한고려요소들인공지능을위한플랫폼토탈솔루션', metadata={'source': 'docs/AF_회사소개서.pdf', 'page': 4})]"
            ]
          },
          "metadata": {},
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"파트너는 누구인가?\"\n",
        "result = qa({\"query\": query})"
      ],
      "metadata": {
        "id": "DR_qIQbvY5Kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"result\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fCdDC_-MZCeF",
        "outputId": "2e820380-1f99-40af-9398-800dae8723d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 휴먼플래닛이 인공지능팩토리의 파트너입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"source_documents\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxMVJ2bMZDco",
        "outputId": "3d6e1d66-42dc-4e00-ae74-4d134f703b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='인공지능팩토리의파트너\\n02\\n휴먼플래닛', metadata={'source': 'docs/AF_회사소개서.pdf', 'page': 2}),\n",
              " Document(page_content='Company Profile\\n인공지능팩토리회사소개서', metadata={'source': 'docs/AF_회사소개서.pdf', 'page': 0}),\n",
              " Document(page_content='05WHY AI FACTORY?전문성있는AI 컨설팅AI기술을도입하고싶지만, 어디부터어떻게적용해야할지막막한분들께인공지능팩토리는최고의파트너입니다. 업계전문가의수준높은컨설팅을통해, 문제정의부터최적화관리까지진정한의미의토탈솔루션을제공합니다.독보적인인공지능모델& 데이터평가검증역량인공지능팩토리는창업이후1년만에20개이상의고객사와함께경진대회개최및모델을개발검증해왔습니다. 다양한산업군경험과전문가기반의평가검증역량으로믿을수있는결과물을드립니다.마무리까지확실한유지보수관리인공지능팩토리는신뢰를중요시합니다. 단순히결과물을전달하는데서끝나지않고사후관리까지담당하여최적화된상태로인공지능모델이이용되도록합니다.', metadata={'source': 'docs/AF_회사소개서.pdf', 'page': 5}),\n",
              " Document(page_content='사업명 -\\n과제명 입자결정 3차원분석모델및Crack 검출모델개발\\n발주기관 LG화학주관기관 ㈜인공지능팩토리\\n공동개발기관 -\\n사업기간 ❖2021년03월15일~ 2021년09월01일\\n사업목표❖[입자 3차원분석모델] 이온통로가되는음극재입자의벡터기반방향성정보\\n를계량화하고 이를시각화하는 모듈개발\\n❖[입자 Crack 검출] 셀의표본이미지로부터 정상입자와균열이발생한입자를\\n탐지하여 계량적지표를산출할수있는 AI 모델개발\\n사업내용❖입자 3차원분석모델개발\\n➢이온통로가되는음극재입자의벡터기반방향성정보를계량화하고 이를\\n시각화하는 모듈개발\\n■3D 극성히스토그램 시각화모듈개발\\n■벡터그룹이 3D 공간에서 가리키는 위치와선호하는 방향이있는지를\\n연구자가 직관적으로 파악할수있도록결과물을 빠르고손쉽게시각화\\n■Matlab 코드(https://github.com/NREL/FIB -SEM -EBSD -particle -scale -\\nanalysis )를실행파일로 생생한뒤, 이를 Python에서구동하도록 설계. \\n즉, Matlab 코드를코어로모듈화시키고데이터입력및구동처리는\\nPython으로개발\\n❖입자 Crack 검출모델개발\\n➢셀의표본이미지로부터 정상입자와균열이발생한입자를탐지하여 계량\\n적지표를산출할수있는 AI 모델개발\\n■입력된이미지가운데정상입자와균열입자를검출\\n■이미지내입자들을 모두탐색한다음해당입자내에균열이존재하는\\n지유무를판단하는 Two-step 방식을활용 (입자 Segmentation → 균열\\n입자판단)\\n●Semantic Segmentation 방식을활용하여 전체입자검출\\n●후처리를 통해검출된입자영역가운데균열이있는영역구분\\n❖인터페이스 구성\\n➢사용이용이하도록 목적에맞는인터페이스 구성\\n■Drag & Drop 방식의개별파일검출용 Web UI 인터페이스\\n■다수데이터일괄처리에용이한 OS 커맨드라인 API 등\\n< 입자 3차원분석 >\\n< 입자 Crack 검출 >', metadata={'source': 'docs/인공지능팩토리_개발용역_실적_요약서.pdf', 'page': 8})]"
            ]
          },
          "metadata": {},
          "execution_count": 294
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "atiHtIqNZD3a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
