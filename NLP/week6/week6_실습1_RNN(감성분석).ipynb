{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa6fa96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  So there is no way for me to plug it in here i...  0\n",
       "1                        Good case, Excellent value.  1\n",
       "2                             Great for the jawbone.  1\n",
       "3  Tied to charger for conversations lasting more...  0\n",
       "4                                  The mic is great.  1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "df = pd.read_csv('amazon_cells_labelled.txt', sep='\\t', header=None)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "537a04c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      So there is no way for me to plug it in here i...\n",
      "1                            Good case, Excellent value.\n",
      "2                                 Great for the jawbone.\n",
      "3      Tied to charger for conversations lasting more...\n",
      "4                                      The mic is great.\n",
      "                             ...                        \n",
      "995    The screen does get smudged easily because it ...\n",
      "996    What a piece of junk.. I lose more calls on th...\n",
      "997                         Item Does Not Match Picture.\n",
      "998    The only thing that disappoint me is the infra...\n",
      "999    You can not answer calls with the unit, never ...\n",
      "Name: 0, Length: 1000, dtype: object\n",
      "plug_idx: 155\n",
      "tok.index_word[plug_idx] plug\n",
      "{'the': 1, 'i': 2, 'and': 3, 'it': 4, 'is': 5, 'a': 6, 'this': 7, 'to': 8, 'phone': 9, 'my': 10, 'for': 11, 'of': 12, 'not': 13, 'with': 14, 'very': 15, 'great': 16, 'was': 17, 'on': 18, 'in': 19, 'that': 20, 'good': 21, 'have': 22, 'you': 23, 'product': 24, 'quality': 25, 'had': 26, 'headset': 27, 'works': 28, 'battery': 29, 'but': 30, 'as': 31, 'sound': 32, 'so': 33, 'are': 34, 'well': 35, 'one': 36, 'all': 37, 'use': 38, 'ear': 39, 'has': 40, 'would': 41, 'work': 42, 'from': 43, 'your': 44, 'like': 45, 'be': 46, 'me': 47, 'case': 48, 'if': 49, 'than': 50, \"i've\": 51, \"don't\": 52, 'no': 53, 'excellent': 54, 'up': 55, 'time': 56, \"it's\": 57, 'after': 58, 'price': 59, 'recommend': 60, 'does': 61, 'really': 62, '2': 63, 'at': 64, 'or': 65, 'best': 66, 'out': 67, 'only': 68, 'service': 69, 'get': 70, 'when': 71, 'nice': 72, \"i'm\": 73, 'also': 74, 'too': 75, 'just': 76, 'any': 77, 'new': 78, 'love': 79, 'these': 80, 'worked': 81, 'am': 82, 'charger': 83, 'more': 84, 'money': 85, 'do': 86, 'can': 87, 'first': 88, 'buy': 89, 'item': 90, 'better': 91, 'an': 92, 'ever': 93, 'car': 94, 'bluetooth': 95, 'about': 96, 'even': 97, 'because': 98, 'easy': 99, 'then': 100, 'what': 101, 'comfortable': 102, 'bought': 103, 'now': 104, 'they': 105, 'reception': 106, 'could': 107, \"doesn't\": 108, 'its': 109, 'did': 110, 'used': 111, 'poor': 112, 'been': 113, 'happy': 114, 'which': 115, 'will': 116, 'there': 117, 'waste': 118, 'two': 119, 'charge': 120, 'made': 121, 'still': 122, 'off': 123, 'bad': 124, 'purchase': 125, 'few': 126, 'cell': 127, 'while': 128, 'worst': 129, 'them': 130, 'far': 131, 'long': 132, 'problem': 133, 'life': 134, 'fine': 135, 'camera': 136, 'calls': 137, 'enough': 138, 'thing': 139, 'device': 140, 'piece': 141, 'got': 142, 'same': 143, 'problems': 144, 'right': 145, 'volume': 146, 'again': 147, 'hear': 148, 'make': 149, 'clear': 150, 'much': 151, 'using': 152, 'motorola': 153, 'fit': 154, 'plug': 155, 'design': 156, 'makes': 157, 'other': 158, 'working': 159, 'fits': 160, 'into': 161, 'think': 162, 'people': 163, 'phones': 164, 'disappointed': 165, 'pretty': 166, 'looks': 167, 'call': 168, \"couldn't\": 169, 'screen': 170, 'over': 171, 'terrible': 172, 'impressed': 173, '5': 174, 'highly': 175, 'how': 176, 'days': 177, 'months': 178, 'years': 179, 'everything': 180, 'cool': 181, 'wear': 182, '1': 183, 'lot': 184, 'cheap': 185, 'customer': 186, 'low': 187, 'however': 188, 'amazon': 189, 'by': 190, 'last': 191, 'without': 192, 'talk': 193, 'little': 194, 'never': 195, '3': 196, 'their': 197, 'verizon': 198, 'buttons': 199, 'broke': 200, 'found': 201, 'tried': 202, 'light': 203, 'jabra': 204, 'small': 205, 'voice': 206, 'look': 207, 'being': 208, 'back': 209, 'horrible': 210, 'year': 211, 'junk': 212, 'unit': 213, 'way': 214, 'several': 215, 'say': 216, 'went': 217, 'most': 218, \"didn't\": 219, 'audio': 220, 'dropped': 221, 'we': 222, 'loud': 223, 'real': 224, 'since': 225, 'big': 226, 'headsets': 227, 'gets': 228, 'down': 229, 'both': 230, 'completely': 231, 'software': 232, 'some': 233, 'internet': 234, 'useless': 235, 'company': 236, 'nokia': 237, 'quite': 238, 'looking': 239, 'take': 240, 'go': 241, 'minutes': 242, 'going': 243, 'three': 244, 'simple': 245, 'ears': 246, 'need': 247, 'picture': 248, 'priced': 249, 'want': 250, 'end': 251, 'headphones': 252, 'find': 253, 'within': 254, 'received': 255, 'black': 256, 'around': 257, 'signal': 258, 'perfectly': 259, 'less': 260, 'put': 261, 'every': 262, 'stay': 263, 'before': 264, 'cable': 265, 'hands': 266, 'came': 267, 'crap': 268, 'anyone': 269, 'difficult': 270, 'samsung': 271, 'value': 272, 'line': 273, 'razr': 274, 'original': 275, 'started': 276, 'charging': 277, 'mobile': 278, 'helpful': 279, 'hold': 280, 'sure': 281, 'turn': 282, 'sturdy': 283, 'different': 284, 'week': 285, 'feels': 286, 'arrived': 287, 'quickly': 288, 'expect': 289, 'definitely': 290, 'free': 291, 'shipping': 292, 'pictures': 293, 'high': 294, 'strong': 295, 'pleased': 296, 'job': 297, 'weeks': 298, 'hours': 299, 'know': 300, 'kind': 301, 'charm': 302, 'awesome': 303, 'where': 304, 'overall': 305, 'color': 306, 'part': 307, 'range': 308, \"i'd\": 309, 'disappointment': 310, 'important': 311, 'return': 312, 'feature': 313, 'many': 314, 'old': 315, 'anything': 316, 'couple': 317, 'disappointing': 318, 'belt': 319, 'data': 320, 'having': 321, 'especially': 322, 'keep': 323, 'plastic': 324, 'another': 325, 'clarity': 326, 'nothing': 327, 'hard': 328, 'always': 329, 'replace': 330, 'none': 331, 'cannot': 332, 'cases': 333, 'connection': 334, \"can't\": 335, 'easily': 336, 'here': 337, 'mic': 338, 'decent': 339, 'sending': 340, 'must': 341, 'were': 342, 'clip': 343, 'blue': 344, 'place': 345, 'absolutely': 346, 'bars': 347, 'she': 348, 'instructions': 349, 'left': 350, 'hate': 351, 'kept': 352, 'performance': 353, 'seems': 354, 'should': 355, 'keyboard': 356, 'actually': 357, 'support': 358, 'player': 359, 'later': 360, 'purchased': 361, 'holds': 362, 'bargain': 363, 'order': 364, 'leather': 365, 'fast': 366, 'comfortably': 367, 'set': 368, 'glad': 369, 'goes': 370, 'tool': 371, 'obviously': 372, 'side': 373, '10': 374, 'lasts': 375, 'able': 376, 'lightweight': 377, 'expected': 378, 'mistake': 379, 'worth': 380, 'earpiece': 381, 'either': 382, 'unreliable': 383, 'family': 384, 'seller': 385, 'plantronics': 386, 'buying': 387, 'try': 388, 'weak': 389, 'lg': 390, 'sucks': 391, 'ago': 392, 'times': 393, 'easier': 394, 'face': 395, 'others': 396, 'wanted': 397, 'deal': 398, 'satisfied': 399, 'comes': 400, 'rather': 401, 'away': 402, 'unfortunately': 403, 'those': 404, 'store': 405, 'own': 406, 'cingular': 407, 't': 408, 'ringtones': 409, 'said': 410, 'day': 411, 'treo': 412, 'usb': 413, 'extra': 414, 'awful': 415, 'unless': 416, 'jawbone': 417, 'conversations': 418, 'contacts': 419, 'static': 420, 'though': 421, 'who': 422, 'everyone': 423, 'pair': 424, 'yet': 425, 'below': 426, 'pocket': 427, 'pc': 428, 'provided': 429, 'included': 430, 'worthless': 431, 'thats': 432, 'features': 433, 'protection': 434, 'instead': 435, 'seconds': 436, '510': 437, 'perhaps': 438, 'seriously': 439, \"phone's\": 440, 'front': 441, 'trouble': 442, 'choice': 443, 'home': 444, 'beautiful': 445, 'longer': 446, 'packaged': 447, 'construction': 448, 'super': 449, 'ease': 450, 'dont': 451, 'plan': 452, 'decision': 453, 'match': 454, 'between': 455, 'fall': 456, 'such': 457, 'wife': 458, 'display': 459, 'rocks': 460, 'may': 461, 'setup': 462, 'earpieces': 463, 'bt': 464, 'getting': 465, 'almost': 466, 'avoid': 467, 'earbud': 468, 'failed': 469, 'coverage': 470, 'drops': 471, 'area': 472, 'forever': 473, 'description': 474, 'fantastic': 475, 'sharp': 476, 'chargers': 477, 'handsfree': 478, 'network': 479, 'slow': 480, 'once': 481, 'lost': 482, 'replacement': 483, 'extremely': 484, 'simply': 485, 'thought': 486, 'reasonably': 487, 'form': 488, 'experience': 489, \"there's\": 490, 'ordered': 491, 'sony': 492, 'market': 493, 'comfort': 494, 'probably': 495, 'drain': 496, 'poorly': 497, 'charged': 498, 'scratched': 499, 'microphone': 500, 'care': 501, 'lacking': 502, 'uncomfortable': 503, 'plugged': 504, 'flip': 505, 'wireless': 506, 'happier': 507, 'trying': 508, 'finally': 509, 'give': 510, 'dead': 511, 'oh': 512, 'might': 513, 'q': 514, 'size': 515, \"wasn't\": 516, 'expensive': 517, 'turned': 518, 'wearing': 519, 'computer': 520, 'under': 521, 'results': 522, 'wrong': 523, 'noise': 524, 'given': 525, 'star': 526, 'holster': 527, 'palm': 528, 'refund': 529, 'drop': 530, 'above': 531, 'through': 532, 'speaker': 533, 'sprint': 534, 'feel': 535, 'needed': 536, 'plus': 537, 'pay': 538, 'tinny': 539, 'pairing': 540, 'iphone': 541, 'despite': 542, 'outlet': 543, 'break': 544, 'beep': 545, 'us': 546, 'lasting': 547, 'wasted': 548, 'he': 549, 'extended': 550, 'notice': 551, 'tooth': 552, 'advise': 553, 'website': 554, 'fire': 555, 'run': 556, \"that's\": 557, 'owned': 558, '7': 559, 'pull': 560, 'unusable': 561, 'least': 562, 'book': 563, 'regarding': 564, 'returned': 565, 'turns': 566, 'pda': 567, 'large': 568, 'essentially': 569, 'forget': 570, 'tech': 571, 'particular': 572, 'party': 573, 'clearly': 574, 'mp3': 575, 'cover': 576, 'let': 577, 'lock': 578, 'died': 579, 'glasses': 580, 'sometimes': 581, 'series': 582, 'quiet': 583, 'person': 584, 'saying': 585, 'docking': 586, 'station': 587, 'd807': 588, 'advertised': 589, 'handy': 590, '6': 591, 'loves': 592, 'cheaper': 593, 'costs': 594, 'play': 595, 'music': 596, 'buyer': 597, 'beware': 598, 'pros': 599, 'white': 600, 'huge': 601, 'flaw': 602, 'although': 603, 'impressive': 604, 'resolution': 605, 'ask': 606, 'slim': 607, 'sex': 608, 'sleek': 609, 'full': 610, 'number': 611, 'keypad': 612, 'unhappy': 613, 'done': 614, 'basically': 615, 'careful': 616, 'logitech': 617, 'stuff': 618, 'house': 619, 'recognition': 620, 'tremendous': 621, 'during': 622, 'experienced': 623, 'takes': 624, 'literally': 625, 'stated': 626, 'hoping': 627, 'blackberry': 628, 'sounds': 629, 'technology': 630, \"wouldn't\": 631, 'wired': 632, 'previous': 633, 'w810i': 634, 'superb': 635, 'maintain': 636, 'graphics': 637, 'button': 638, 'thank': 639, 'igo': 640, 'tips': 641, 'connected': 642, \"wife's\": 643, 'storage': 644, 'buzzing': 645, 'override': 646, 'functionality': 647, 'incredible': 648, 'ring': 649, 'dropping': 650, 'thin': 651, 'nearly': 652, 'bother': 653, 'room': 654, 'issues': 655, 'felt': 656, 'embarrassing': 657, 'consumer': 658, 'background': 659, 'certainly': 660, 'usually': 661, 'mess': 662, 'bit': 663, 'tell': 664, 'excited': 665, 'additional': 666, 'gels': 667, 'whatsoever': 668, 'purpose': 669, 'secure': 670, 'appears': 671, 'smell': 672, 'caused': 673, 'flimsy': 674, 'month': 675, 'flawlessly': 676, 'stars': 677, 'whole': 678, 'adorable': 679, 'wise': 680, 'gotten': 681, 'driving': 682, 'dialing': 683, 'cant': 684, 'neither': 685, 'games': 686, 'ipod': 687, 'recharge': 688, 'save': 689, \"i'll\": 690, 'along': 691, 'starts': 692, 'ringing': 693, 'reason': 694, 'auto': 695, 'push': 696, 'sides': 697, 'skype': 698, 'shipped': 699, 'exactly': 700, 'waiting': 701, 'stupid': 702, 'noticed': 703, 'att': 704, 'breaks': 705, 'effect': 706, 'model': 707, 'warning': 708, 'dying': 709, 'alone': 710, 'install': 711, 'purchasing': 712, 'moto': 713, 'figure': 714, '20': 715, 'reading': 716, 'sunglasses': 717, 'returning': 718, 'cumbersome': 719, 'switch': 720, 'worthwhile': 721, 'understand': 722, 'batteries': 723, \"won't\": 724, 'user': 725, 'friendly': 726, 'ability': 727, 'receiving': 728, 'exchanged': 729, 'cellphone': 730, 'described': 731, 'im': 732, 'defective': 733, 'unacceptable': 734, 'review': 735, 'catching': 736, 'amazed': 737, 'timeframe': 738, 'complaint': 739, 'things': 740, 'ended': 741, 'accidentally': 742, 'touch': 743, 'listening': 744, 'took': 745, 'conversation': 746, 'eargels': 747, 'seem': 748, 'numerous': 749, 'please': 750, 'barely': 751, 'joke': 752, 'forced': 753, 'holding': 754, 'broken': 755, 'breaking': 756, '50': 757, 'coming': 758, 'quick': 759, 'operate': 760, 'paired': 761, 'come': 762, 'brand': 763, 'red': 764, 'reviews': 765, 'echo': 766, 'wind': 767, 'told': 768, 'warranty': 769, 'something': 770, 'bar': 771, 'placed': 772, 'spring': 773, 'tries': 774, 'download': 775, 'access': 776, 'third': 777, 'flash': 778, 'tones': 779, 'chinese': 780, 'crisp': 781, 'video': 782, 'hour': 783, 'accept': 784, 'allows': 785, 'power': 786, 'wall': 787, 'etc': 788, 'hand': 789, 'cut': 790, 'sizes': 791, '4': 792, 'next': 793, 'protector': 794, 'date': 795, 'bottom': 796, 'sounded': 797, 'together': 798, 'feet': 799, 'send': 800, 'current': 801, 'says': 802, 'answer': 803, 'laptop': 804, 'inside': 805, 'normal': 806, 'making': 807, 'fails': 808, 'lose': 809, 'ok': 810, 'wow': 811, 'converter': 812, 'tied': 813, '45': 814, 'major': 815, 'jiggle': 816, 'dozen': 817, 'hundred': 818, 'imagine': 819, 'fun': 820, 'each': 821, 'owner': 822, 'needless': 823, 'seperated': 824, 'mere': 825, 'ft': 826, 'excessive': 827, 'garbled': 828, 'odd': 829, 'fooled': 830, 'clicks': 831, 'wonder': 832, 'mechanism': 833, \"motorola's\": 834, 'followed': 835, 'directions': 836, 'kindle': 837, 'loved': 838, 'commercials': 839, 'misleading': 840, 'mother': 841, 'combination': 842, 'couldnt': 843, 'earphone': 844, 'breakage': 845, 'unacceptible': 846, 'ideal': 847, 'whose': 848, 'sensitive': 849, 'moving': 850, 'freeway': 851, 'speed': 852, 'contract': 853, 'ac': 854, 'juice': 855, 'highy': 856, 'recommended': 857, 'mins': 858, 'short': 859, '680': 860, '2mp': 861, 'pics': 862, 'garbage': 863, 'mind': 864, 'gonna': 865, 'arguing': 866, 'bulky': 867, 'usable': 868, 'world': 869, 'useful': 870, 'machine': 871, 'neat': 872, 'gadget': 873, 'reasonable': 874, 'e': 875, 'stream': 876, 'submerged': 877, '15': 878, 'complaints': 879, \"microsoft's\": 880, 'faceplates': 881, 'elegant': 882, 'angle': 883, 'drawback': 884, 'pause': 885, 'skip': 886, 'songs': 887, 'activated': 888, 'suddenly': 889, 'ipods': 890, 'situations': 891, 'bmw': 892, 'fairly': 893, 'hearing': 894, 'wrongly': 895, 'everyday': 896, 'intended': 897, 'runs': 898, 'boy': 899, 'loads': 900, 'greater': 901, 'buds': 902, 'waaay': 903, 'bluetooths': 904, 'listener': 905, 'integrated': 906, 'seamlessly': 907, 'flush': 908, 'toilet': 909, 'supposedly': 910, '375': 911, 'apparently': 912, 'styles': 913, 'correctly': 914, '350': 915, 'jabra350': 916, 'rated': 917, 'megapixels': 918, 'renders': 919, 'images': 920, 'expectations': 921, 'relatively': 922, 'purcashed': 923, 'geeky': 924, 'toast': 925, 'oozes': 926, 'embedded': 927, 'stylish': 928, 'compromise': 929, 'qwerty': 930, 'basic': 931, 'winner': 932, 'simpler': 933, 'iam': 934, 'disapoinment': 935, 'realize': 936, 'accompanied': 937, 'brilliant': 938, 'nicely': 939, 'damage': 940, 'definitly': 941, 'majority': 942, 'peachy': 943, 'keen': 944, 'upstairs': 945, 'basement': 946, 'minute': 947, 'reccomendation': 948, 'relative': 949, 'items': 950, 'sudden': 951, 'linking': 952, '8530': 953, 'curve': 954, 'funny': 955, 'seemed': 956, 'sketchy': 957, 'messages': 958, 'web': 959, 'browsing': 960, 'significantly': 961, 'faster': 962, 'build': 963, 'unlike': 964, 's': 965, 'colors': 966, 'whine': 967, 'communications': 968, 'communicate': 969, 'monkeys': 970, \"shouldn't\": 971, 'share': 972, 'dna': 973, 'copy': 974, 'humans': 975, 'bougth': 976, 'l7c': 977, 'mode': 978, 'wasting': 979, 'file': 980, 'browser': 981, 'offers': 982, 'options': 983, 'needs': 984, 'hs850': 985, 'whether': 986, 'latest': 987, 'os': 988, 'v1': 989, '15g': 990, 'likes': 991, 'crawl': 992, 'recognizes': 993, 'bluetoooth': 994, 'thorn': 995, 'abhor': 996, 'recently': 997, 'disconnected': 998, '13': 999, 'bucks': 1000, 'check': 1001, 'mail': 1002, 'night': 1003, 'backlight': 1004, 'message': 1005, 'tone': 1006, 'lately': 1007, 'wit': 1008, 'hit': 1009, 'weight': 1010, 'hardly': 1011, \"you'll\": 1012, 'pleather': 1013, 'deaf': 1014, 'prettier': 1015, 'incredibly': 1016, 'investment': 1017, 'strange': 1018, 'ticking': 1019, 'noises': 1020, 'ends': 1021, 'electronics': 1022, 'available': 1023, 'fm': 1024, 'transmitters': 1025, 'h500': 1026, 'mega': 1027, 'pixel': 1028, 'good7': 1029, 'transmit': 1030, 'contacting': 1031, 'dollar': 1032, 'learned': 1033, 'lesson': 1034, 'online': 1035, 'anyway': 1036, 'earbugs': 1037, 'means': 1038, 'roam': 1039, 'living': 1040, 'crack': 1041, 'infatuated': 1042, 'freezes': 1043, 'frequently4': 1044, 'mostly': 1045, 'child': 1046, 'tick': 1047, 'headbands': 1048, 'hair': 1049, 'ericsson': 1050, 'favorite': 1051, 'purchases': 1052, 'authentic': 1053, 'shine': 1054, 'cute': 1055, 'calendar': 1056, 'sync': 1057, 'defeats': 1058, 'penny': 1059, 'wallet': 1060, 'type': 1061, 'excrutiatingly': 1062, 'aspect': 1063, 'glove': 1064, 'durable': 1065, 'o': 1066, 'gosh': 1067, 'attractive': 1068, 'factor': 1069, 'rubber': 1070, 'petroleum': 1071, 'unbearable': 1072, 'scary': 1073, 'stereo': 1074, 'absolutel': 1075, '8': 1076, 'potentially': 1077, 'fry': 1078, 'giving': 1079, 'gave': 1080, 'reversible': 1081, 'rotating': 1082, 'our': 1083, 'contstruct': 1084, 'hinge': 1085, 'installed': 1086, 'overnite': 1087, 'thru': 1088, 'handset': 1089, 'cat': 1090, 'attacked': 1091, 'protective': 1092, 'strip': 1093, 'destroying': 1094, 'razor': 1095, 'v3i': 1096, 'someone': 1097, 'shouldve': 1098, 'invented': 1099, 'sooner': 1100, 'engineered': 1101, 'clever': 1102, 'complained': 1103, \"headset's\": 1104, '2160': 1105, 'tracfone': 1106, 'instruction': 1107, 'manual': 1108, 'alarm': 1109, 'clock': 1110, 'removing': 1111, 'antena': 1112, 'compared': 1113, 'compliments': 1114, 'state': 1115, 'allow': 1116, 'usage': 1117, 'immediately': 1118, 'ngage': 1119, 'earbuds': 1120, 'riingtones': 1121, 'rip': 1122, 'frequentyly': 1123, 'adhesive': 1124, 'inexpensive': 1125, 'practically': 1126, 'add': 1127, 'boost': 1128, 'concrete': 1129, 'knock': 1130, 'wood': 1131, 'transformed': 1132, 'organizational': 1133, 'capability': 1134, 'sitting': 1135, 'vehicle': 1136, 'cradle': 1137, 'jerks': 1138, 'los': 1139, 'angeles': 1140, 'starter': 1141, 'loudspeaker': 1142, 'option': 1143, 'bumpers': 1144, 'lights': 1145, 'appealing': 1146, 'improve': 1147, 'leaks': 1148, 'hot': 1149, 'according': 1150, 'called': 1151, 'applifies': 1152, 'specially': 1153, 'transmission': 1154, 's11': 1155, 'finished': 1156, 'drivng': 1157, 'reverse': 1158, 'tape': 1159, 'embarassing': 1160, 'hurt': 1161, 'protects': 1162, 'average': 1163, 'operates': 1164, 'soyo': 1165, 'self': 1166, 'portraits': 1167, 'outside': 1168, 'exterior': 1169, 'mentioned': 1170, 'gadgets': 1171, 'magical': 1172, 'help': 1173, 'promptly': 1174, 'comparably': 1175, 'offering': 1176, 'today': 1177, 'encourage': 1178, \"you'd\": 1179, 'effective': 1180, 'recieve': 1181, 'prompt': 1182, 'cradles': 1183, 'kits': 1184, 'excelent': 1185, 'cingulair': 1186, 'nicer': 1187, 'era': 1188, 'colored': 1189, 'hoursthe': 1190, 'thereplacement': 1191, '2000': 1192, 'cheaply': 1193, 'distorted': 1194, 'yell': 1195, 'forgot': 1196, 'mention': 1197, 'weird': 1198, 'iriver': 1199, 'spinn': 1200, 'fond': 1201, 'magnetic': 1202, 'strap': 1203, 'psyched': 1204, 'appointments': 1205, 'note': 1206, 'appearance': 1207, 'bland': 1208, 'sanyo': 1209, 'survived': 1210, 'dozens': 1211, 'blacktop': 1212, 'ill': 1213, 'earphones': 1214, 'finds': 1215, 'enter': 1216, 'modest': 1217, 'cellular': 1218, 'wish': 1219, 'awsome': 1220, 'drained': 1221, 'earpad': 1222, 'displeased': 1223, 'defect': 1224, 'risk': 1225, 'built': 1226, 'restored': 1227, 'jx': 1228, 'searched': 1229, 'key': 1230, 'pad': 1231, 'lit': 1232, 'portable': 1233, 'colleague': 1234, 'fully': 1235, 'bed': 1236, 'wi': 1237, 'fi': 1238, 'morning': 1239, 'memory': 1240, 'card': 1241, 'hat': 1242, 'timely': 1243, 'shipment': 1244, 'solid': 1245, 'surefire': 1246, 'gx2': 1247, 'bt50': 1248, 'buyers': 1249, 'remorse': 1250, 'accessoryone': 1251, 'inexcusable': 1252, 'changing': 1253, 'carriers': 1254, 'tmobile': 1255, 'update': 1256, 'procedure': 1257, 'motorolas': 1258, 'delivery': 1259, 'vx9900': 1260, 'env': 1261, 'rocketed': 1262, 'destination': 1263, 'unknown': 1264, 'conditions': 1265, 'usefulness': 1266, \"verizon's\": 1267, 'bills': 1268, 'pricing': 1269, 'plans': 1270, 'overnight': 1271, 'regret': 1272, 'pitiful': 1273, 'respect': 1274, 'stuck': 1275, 'max': 1276, 'mute': 1277, 'hybrid': 1278, 'palmtop': 1279, 'excels': 1280, 'roles': 1281, 'bt250v': 1282, 'liked': 1283, '11': 1284, 'bose': 1285, 'cancelling': 1286, 'amazing': 1287, 'nyc': 1288, 'commuter': 1289, 'photo': 1290, 'ad': 1291, 'earlier': 1292, 'noted': 1293, 'happens': 1294, 'frog': 1295, 'eye': 1296, 'pushed': 1297, 'function': 1298, 'aluminum': 1299, 'vx': 1300, 'protected': 1301, 'handheld': 1302, 'tools': 1303, 'sturdiness': 1304, 'orders': 1305, 'source': 1306, 'waterproof': 1307, 'standard': 1308, 'thanks': 1309, 'sliding': 1310, 'edge': 1311, 'pants': 1312, 'pockets': 1313, 'ugly': 1314, 'shield': 1315, 'incrediable': 1316, 'improvement': 1317, 'refuse': 1318, 'activate': 1319, 'gentle': 1320, 'threw': 1321, 'window': 1322, 'inches': 1323, 'kitchen': 1324, 'counter': 1325, 'cracked': 1326, 'laughing': 1327, 'trunk': 1328, 'carried': 1329, 'hitch': 1330, 'practical': 1331, 'ample': 1332, 'channel': 1333, 'directly': 1334, 'increase': 1335, 'ones': 1336, 'properly': 1337, 'missed': 1338, 'sucked': 1339, 'shifting': 1340, 'bubbling': 1341, 'peeling': 1342, 'scratch': 1343, 'droid': 1344, 'zero': 1345, 'exercise': 1346, 'frustration': 1347, 'earset': 1348, 'outgoing': 1349, 'total': 1350, 'package': 1351, 'understanding': 1352, 'patient': 1353, 'wirefly': 1354, 'contact': 1355, 'inform': 1356, 'practice': 1357, 'aggravating': 1358, 'friends': 1359, 'enjoy': 1360, 'virgin': 1361, 'muddy': 1362, 'casing': 1363, \"wire's\": 1364, 'insert': 1365, 'glued': 1366, 'slid': 1367, \"isn't\": 1368, 'plantronincs': 1369, 'continues': 1370, 'flawed': 1371, 'disapointing': 1372, 'fourth': 1373, 'hated': 1374, 'fixes': 1375, 'accessing': 1376, 'downloading': 1377, 'performing': 1378, 'functions': 1379, 'constantly': 1380, 'due': 1381, 'happening': 1382, 'stop': 1383, 'adapters': 1384, 'walked': 1385, 'procedures': 1386, 're': 1387, 'wiping': 1388, 'strength': 1389, 'plays': 1390, 'louder': 1391, 'constructed': 1392, 'menus': 1393, 'navigate': 1394, 'recessed': 1395, 'avoiding': 1396, 'smoking': 1397, 'linked': 1398, 'effort': 1399, 'possesed': 1400, 'idea': 1401, 'trash': 1402, 'research': 1403, 'development': 1404, 'division': 1405, 'knows': 1406, \"they're\": 1407, 'doing': 1408, 'killer': 1409, 'course': 1410, 'infuriating': 1411, 'walkman': 1412, 'charges': 1413, 'europe': 1414, 'asia': 1415, 'clipping': 1416, 'deffinitely': 1417, \"cent's\": 1418, 'behing': 1419, '5020': 1420, 'comfortible': 1421, '24': 1422, 'pain': 1423, 'arrival': 1424, 'fraction': 1425, 'crappy': 1426, 'e715': 1427, 'seeen': 1428, 'stopped': 1429, 'interface': 1430, 'decade': 1431, 'compete': 1432, 'designs': 1433, '700w': 1434, 'transceiver': 1435, 'steer': 1436, 'genuine': 1437, 'replacementr': 1438, 'pens': 1439, 'pack': 1440, 'buyit': 1441, 'beats': 1442, 'fingers': 1443, 'believe': 1444, 'steep': 1445, 'point': 1446, 'normally': 1447, 'apart': 1448, 'haul': 1449, 'dissapointing': 1450, 'originally': 1451, 'discarded': 1452, 'players': 1453, 'posted': 1454, 'detailed': 1455, 'comments': 1456, 'grey': 1457, 'guess': 1458, 'existing': 1459, 'cds': 1460, 'surprised': 1461, 'fabulous': 1462, 'currently': 1463, 'shooters': 1464, 'delay': 1465, 'messes': 1466, 'bitpim': 1467, 'program': 1468, 'transfer': 1469, 'accessory': 1470, 'manufacturer': 1471, 'performed': 1472, 'muffled': 1473, 'incoming': 1474, 'severe': 1475, 'resistant': 1476, 'overly': 1477, 'contacted': 1478, 'produce': 1479, 'receipt': 1480, 'luck': 1481, 'linksys': 1482, 'exchange': 1483, 'refurb': 1484, 'snug': 1485, 'heavy': 1486, 'keeps': 1487, 'falling': 1488, 'utter': 1489, 'promised': 1490, 'loop': 1491, 'tiny': 1492, 'four': 1493, 'latch': 1494, 'visor': 1495, 'address': 1496, 'reboots': 1497, 'rate': 1498, 'tungsten': 1499, 'e2': 1500, 'flipphones': 1501, 'designed': 1502, 'smoothly': 1503, 'study': 1504, 'interested': 1505, 'sins': 1506, 'industrial': 1507, 'happened': 1508, 'tracking': 1509, 'detachable': 1510, 'continue': 1511, 'periodically': 1512, 'somehow': 1513, 'upload': 1514, 'locks': 1515, 'screens': 1516, 'randomly': 1517, 'locked': 1518, 'truly': 1519, '325': 1520, 'worn': 1521, 'ringer': 1522, 'choices': 1523, 'acceptable': 1524, 'balance': 1525, 'ready': 1526, 'prime': 1527, 'upbeat': 1528, 'forgeries': 1529, 'abound': 1530, 'explain': 1531, 'jack': 1532, 'ca': 1533, '42': 1534, 'smallest': 1535, 'stays': 1536, 'biggest': 1537, 'drains': 1538, 'superfast': 1539, 'ergonomic': 1540, 'theory': 1541, 'stand': 1542, 'clips': 1543, 'occupied': 1544, 'distracting': 1545, 'entire': 1546, 'except': 1547, 'cbr': 1548, 'mp3s': 1549, 'preferably': 1550, 'ripped': 1551, 'windows': 1552, 'media': 1553, 'beat': 1554, 'shots': 1555, 'sos': 1556, 'signals': 1557, 'connect': 1558, 'mini': 1559, 'near': 1560, 'open': 1561, 'allowing': 1562, 'startac': 1563, 'regretted': 1564, 'outperform': 1565, 'china': 1566, 'v325i': 1567, 'numbers': 1568, 'sim': 1569, '3o': 1570, 'r': 1571, 'crashed': 1572, 'replaced': 1573, 'quit': 1574, '18': 1575, '4s': 1576, 'connecting': 1577, 'multiple': 1578, 'sources': 1579, 'imac': 1580, 'external': 1581, 'elsewhere': 1582, 'bells': 1583, 'whistles': 1584, 'mediocre': 1585, 'via': 1586, 'slide': 1587, 'grip': 1588, 'prevents': 1589, 'slipping': 1590, 'span': 1591, 'exclaim': 1592, 'whoa': 1593, 'tv': 1594, 'corded': 1595, 'freedom': 1596, 'passed': 1597, 'mark': 1598, 'shows': 1599, 'signs': 1600, '100': 1601, 'functional': 1602, 'soft': 1603, 'tight': 1604, 'shape': 1605, 'copier': 1606, 'sent': 1607, 'anywhere': 1608, 'sold': 1609, 'units': 1610, 'provides': 1611, 'classy': 1612, 'krussel': 1613, 'tracfonewebsite': 1614, 'toactivate': 1615, 'texas': 1616, 'dit': 1617, '5320': 1618, 'mainly': 1619, 'soon': 1620, 'whatever': 1621, 'blueant': 1622, 'supertooth': 1623, 'metro': 1624, 'pcs': 1625, 'sch': 1626, 'r450': 1627, 'slider': 1628, 'premium': 1629, 'plugs': 1630, 'plenty': 1631, 'capacity': 1632, 'confortable': 1633, 'somewhat': 1634, 'periods': 1635, 'ant': 1636, 'hey': 1637, 'pleasantly': 1638, 'suprised': 1639, 'cost': 1640, 'dustpan': 1641, 'indoors': 1642, 'disposable': 1643, 'puff': 1644, 'smoke': 1645, 'convenient': 1646, 'ride': 1647, 'smoother': 1648, 'nano': 1649, 'son': 1650, 'dissapointed': 1651, 'reccommend': 1652, 'carries': 1653, 'highest': 1654, 'anti': 1655, 'glare': 1656, 'smartphone': 1657, 'wont': 1658, 'atleast': 1659, 'addition': 1660, 'amp': 1661, 'reoccure': 1662, 'somewhere': 1663, 'else': 1664, '12': 1665, 'creaks': 1666, 'wooden': 1667, 'floor': 1668, 'apartment': 1669, 'generally': 1670, 'inconspicuous': 1671, 'boot': 1672, 'slowly': 1673, 'sorry': 1674, 'impossible': 1675, 'refused': 1676, 'upgrade': 1677, 'discount': 1678, 'securly': 1679, 'possibility': 1680, 'double': 1681, 'booking': 1682, 'entertainment': 1683, 'communication': 1684, 'management': 1685, 'activesync': 1686, 'optimal': 1687, 'synchronization': 1688, 'disgusting': 1689, 'coupon': 1690, 'rare': 1691, 'instance': 1692, 'perfect': 1693, 'ps3': 1694, 'five': 1695, 'cheapy': 1696, 'lots': 1697, 'talking': 1698, 'shouting': 1699, 'telephone': 1700, 'yes': 1701, 'shiny': 1702, 'grtting': 1703, '44': 1704, 'until': 1705, 'v3c': 1706, 'thumbs': 1707, 'exceeds': 1708, 'sight': 1709, 'improper': 1710, 'checked': 1711, 'everywhere': 1712, 'ordering': 1713, 'effects': 1714, 'palms': 1715, 'awkward': 1716, 'hoped': 1717, 'father': 1718, 'v265': 1719, 'pads': 1720, 'stops': 1721, 'intermittently': 1722, 'reaching': 1723, 'row': 1724, 'keys': 1725, 'nightmare': 1726, 'describe': 1727, 'speakerphone': 1728, 'cassette': 1729, 'cellphones': 1730, 'planning': 1731, 'dirty': 1732, 'read': 1733, \"other's\": 1734, \"haven't\": 1735, 'products': 1736, 'sensor': 1737, 'reliability': 1738, 'beeping': 1739, 'letting': 1740, 'dieing': 1741, 'ir': 1742, 'cancellation': 1743, 'counterfeit': 1744, 'see': 1745, 'travled': 1746, 'swivel': 1747, 'sister': 1748, 'dual': 1749, '8125': 1750, 'keeping': 1751, 'bottowm': 1752, 'gimmick': 1753, 'opens': 1754, 'top': 1755, 'causing': 1756, 'discomfort': 1757, 'trust': 1758, 'maintains': 1759, 'flawless': 1760, 'devices': 1761, 'utterly': 1762, 'confusing': 1763, 'holder': 1764, 'cutouts': 1765, 'land': 1766, 'loops': 1767, 'material': 1768, 'flaws': 1769, 'exceptional': 1770, 'owning': 1771, 'official': 1772, 'oem': 1773, 'loudest': 1774, 'setting': 1775, 'competitors': 1776, 'show': 1777, 'saved': 1778, 'alot': 1779, 'cuts': 1780, 'totally': 1781, 'unintelligible': 1782, 'word': 1783, 'restart': 1784, 'managed': 1785, 'bend': 1786, 'leaf': 1787, 'metal': 1788, 'stress': 1789, 'leopard': 1790, 'print': 1791, 'wonderfully': 1792, 'wild': 1793, 'saggy': 1794, 'floppy': 1795, 'looses': 1796, 'snap': 1797, '8525': 1798, 'carry': 1799, 'fliptop': 1800, 'loose': 1801, 'wobbly': 1802, 'eventually': 1803, 'receive': 1804, 'seat': 1805, 'fulfills': 1806, 'requirements': 1807, 'fact': 1808, 'rests': 1809, 'lightly': 1810, 'against': 1811, 'websites': 1812, 'rating': 1813, 'cables': 1814, 'lap': 1815, 'controls': 1816, 'accessable': 1817, 'mine': 1818, 'christmas': 1819, 'rest': 1820, 'otherwise': 1821, 'joy': 1822, 'satisifed': 1823, '2005': 1824, 's710a': 1825, 'specs': 1826, 'armband': 1827, 'allot': 1828, 'clearer': 1829, 'keypads': 1830, 'reach': 1831, 'ericson': 1832, 'z500a': 1833, 'motor': 1834, 'control': 1835, 'center': 1836, 'voltage': 1837, 'humming': 1838, 'equipment': 1839, 'certain': 1840, 'places': 1841, 'girl': 1842, 'complain': 1843, 'wake': 1844, 'styling': 1845, 'restocking': 1846, 'fee': 1847, 'darn': 1848, 'lousy': 1849, 'seen': 1850, 'sweetest': 1851, 'securely': 1852, 'hook': 1853, 'directed': 1854, 'canal': 1855, 'unsatisfactory': 1856, 'videos': 1857, 'negatively': 1858, 'adapter': 1859, 'provide': 1860, 'hype': 1861, 'assumed': 1862, 'lense': 1863, 'covered': 1864, 'falls': 1865, 'text': 1866, 'messaging': 1867, 'tricky': 1868, 'painful': 1869, 'lasted': 1870, 'blew': 1871, 'flops': 1872, 'smudged': 1873, 'touches': 1874, 'disappoint': 1875, 'infra': 1876, 'port': 1877, 'irda': 1878}\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "tok = Tokenizer()\n",
    "print(df[0])\n",
    "\n",
    "tok.fit_on_texts(df[0])\n",
    "\n",
    "plug_idx = tok.word_index['plug']\n",
    "print(f\"plug_idx: {plug_idx}\")\n",
    "print(\"tok.index_word[plug_idx]\", tok.index_word[plug_idx])\n",
    "\n",
    "word_to_index = tok.word_index\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cad32786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33,\n",
       " 117,\n",
       " 5,\n",
       " 53,\n",
       " 214,\n",
       " 11,\n",
       " 47,\n",
       " 8,\n",
       " 155,\n",
       " 4,\n",
       " 19,\n",
       " 337,\n",
       " 19,\n",
       " 1,\n",
       " 546,\n",
       " 416,\n",
       " 2,\n",
       " 241,\n",
       " 190,\n",
       " 6,\n",
       " 812]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = tok.texts_to_sequences(df[0])\n",
    "seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0592d5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so there is no way for me to plug it in here in the us unless i go by a converter\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,  33, 117,   5,  53,\n",
       "       214,  11,  47,   8, 155,   4,  19, 337,  19,   1, 546, 416,   2,\n",
       "       241, 190,   6, 812], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  correct import\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "print(' '.join(tok.index_word[i] for i in seq[0]))\n",
    "\n",
    "# 길이를 맞춰주기\n",
    "MAXLEN = max(len(s) for s in seq)\n",
    "pad = pad_sequences(seq, MAXLEN)\n",
    "pad[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f60e9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 30, 8)             15032     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 16)                1600      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,649\n",
      "Trainable params: 16,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 임베딩 토큰화한 pad와 라벨인 df[1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(pad, df[1], test_size=.2, random_state=1234)\n",
    "\n",
    "\n",
    "NUM_WORDS = len(tok.index_word) + 1\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "\n",
    "rnn = Sequential()\n",
    "#  단어를 밀집 벡터로 매핑하는 데 사용되며, 입력 차원, 출력 차원 및 입력 길이가 설정\n",
    "rnn.add(Embedding(input_dim=NUM_WORDS, output_dim=8, input_length=MAXLEN, mask_zero=True))\n",
    "# LSTM 레이어를 모델에 추가\n",
    "rnn.add(LSTM(16, return_sequences=False))\n",
    "# 감정 분석을 위한 이진 분류를 수행하며 시그모이드 활성화 함수\n",
    "rnn.add(Dense(1, activation='sigmoid'))\n",
    "rnn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00f82148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 21:25:34.098583: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 5ms/step - loss: 0.6928 - accuracy: 0.5337\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6888 - accuracy: 0.7050\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6691 - accuracy: 0.8450\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5707 - accuracy: 0.8737\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.9013\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3043 - accuracy: 0.9488\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2426 - accuracy: 0.9575\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1975 - accuracy: 0.9712\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1719 - accuracy: 0.9762\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1314 - accuracy: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29c0b2ef0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "# Adam 옵티마이저: 신경망 모델의 가중치를 업데이트하는 최적화 알고리즘\n",
    "#  이진 분류 문제를 다루기 때문에 이진 교차 엔트로피 손실 함수\n",
    "# 모델을 평가할 때 정확도를 측정\n",
    "rnn.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# 전체 학습 데이터를 10번 반복하여 모델을 학습한다는 것을 의미\n",
    "rnn.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea9a43b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.815"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_rnn = (rnn.predict(X_test) > 0.5)*1\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3006b550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 1s 4ms/step - loss: 0.6927 - accuracy: 0.5113\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.5750\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6655 - accuracy: 0.8012\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5722 - accuracy: 0.8712\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.9050\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.3347 - accuracy: 0.9400\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2534 - accuracy: 0.9625\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2085 - accuracy: 0.9688\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1682 - accuracy: 0.9800\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1352 - accuracy: 0.9862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d132ded0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - 역방향 \n",
    "# 단어처리 순서를 앞에서 뒤로 하는 것이 아니라 역방향으로 뒤에서 앞으로도 할 수 있다. 순환신경망 레이어에 go_backwards=True를 추가해주면 된다.\n",
    "rnn_goback = Sequential()\n",
    "rnn_goback.add(Embedding(input_dim=NUM_WORDS, output_dim=8, input_length=MAXLEN, mask_zero=True))\n",
    "rnn_goback.add(LSTM(16, return_sequences=False, go_backwards=True))\n",
    "rnn_goback.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "rnn_goback.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "rnn_goback.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72465cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.74"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_rnn_goback = (rnn_goback.predict(X_test) > 0.5)*1\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_rnn_goback, y_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d775921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 2s 5ms/step - loss: 0.6926 - accuracy: 0.5325\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.7788\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6647 - accuracy: 0.8487\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5274 - accuracy: 0.8838\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3299 - accuracy: 0.9237\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2229 - accuracy: 0.9638\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1636 - accuracy: 0.9762\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1317 - accuracy: 0.9787\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1061 - accuracy: 0.9862\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1041 - accuracy: 0.9837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d5710550>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # - 양방향\n",
    "# 순방향 RNN과 양방향 RNN을 합치면 양방향 RNN이 된다. Bidirectional을 사용한다.\n",
    "from keras.layers import Bidirectional\n",
    "rnn_bidirec = Sequential()\n",
    "rnn_bidirec.add(Embedding(input_dim=NUM_WORDS, output_dim=8, input_length=MAXLEN, mask_zero=True))\n",
    "rnn_bidirec.add(Bidirectional(LSTM(16, return_sequences=False)))\n",
    "rnn_bidirec.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "rnn_bidirec.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "rnn_bidirec.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13078d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_rnn_bidirec = (rnn_bidirec.predict(X_test) > 0.5)*1\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_rnn_bidirec, y_rnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea736fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 30, 8)             15032     \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 28, 16)            400       \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 16)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,449\n",
      "Trainable params: 15,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 0s 743us/step - loss: 0.6920 - accuracy: 0.5138\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 702us/step - loss: 0.6805 - accuracy: 0.5462\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 805us/step - loss: 0.6648 - accuracy: 0.6513\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 785us/step - loss: 0.6387 - accuracy: 0.7862\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 730us/step - loss: 0.5981 - accuracy: 0.8763\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 725us/step - loss: 0.5414 - accuracy: 0.9350\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 714us/step - loss: 0.4736 - accuracy: 0.9413\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 780us/step - loss: 0.4022 - accuracy: 0.9538\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 709us/step - loss: 0.3353 - accuracy: 0.9513\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 757us/step - loss: 0.2762 - accuracy: 0.9625\n",
      "7/7 [==============================] - 0s 692us/step - loss: 0.4191 - accuracy: 0.8100\n",
      "Test Accuracy: 0.8100000023841858\n"
     ]
    }
   ],
   "source": [
    "# CNN 모델 추가\n",
    "\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Embedding(input_dim=NUM_WORDS, output_dim=8, input_length=MAXLEN))\n",
    "cnn.add(Conv1D(filters=16, kernel_size=3, activation='relu'))\n",
    "cnn.add(GlobalMaxPooling1D())\n",
    "cnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "cnn.summary()\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "cnn.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "accuracy = cnn.evaluate(X_test, y_test)[1]\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3416ea2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, 30, 8)        15032       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 30, 8)        15032       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 28, 16)       400         ['embedding_5[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  (None, 16)           1600        ['embedding_4[0][0]']            \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Global  (None, 16)          0           ['conv1d_1[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32)           0           ['lstm_3[0][0]',                 \n",
      "                                                                  'global_max_pooling1d_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1)            33          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 32,097\n",
      "Trainable params: 32,097\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.6920 - accuracy: 0.5150\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6815 - accuracy: 0.5663\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6646 - accuracy: 0.7875\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6184 - accuracy: 0.7538\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.8263\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3619 - accuracy: 0.9125\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.9538\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1751 - accuracy: 0.9712\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1315 - accuracy: 0.9812\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1081 - accuracy: 0.9887\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.8350\n",
      "Test Accuracy: 0.8349999785423279\n"
     ]
    }
   ],
   "source": [
    "# 앙상블 모델 = LSTM 모델 + CNN 모델\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate\n",
    "\n",
    "\n",
    "lstm_input = Input(shape=(MAXLEN,))\n",
    "lstm_embedding = Embedding(input_dim=NUM_WORDS, output_dim=8, input_length=MAXLEN)(lstm_input)\n",
    "lstm_output = LSTM(16, return_sequences=False)(lstm_embedding)\n",
    "\n",
    "# CNN 모델\n",
    "cnn_input = Input(shape=(MAXLEN,))\n",
    "cnn_embedding = Embedding(input_dim=NUM_WORDS, output_dim=8, input_length=MAXLEN)(cnn_input)\n",
    "cnn_conv = Conv1D(filters=16, kernel_size=3, activation='relu')(cnn_embedding)\n",
    "cnn_pool = GlobalMaxPooling1D()(cnn_conv)\n",
    "\n",
    "# LSTM과 CNN 모델 병합\n",
    "merged = concatenate([lstm_output, cnn_pool])\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 앙상블 모델 생성\n",
    "ensemble_model = Model(inputs=[lstm_input, cnn_input], outputs=output)\n",
    "ensemble_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ensemble_model.summary()\n",
    "\n",
    "# 학습 및 평가\n",
    "ensemble_model.fit([X_train, X_train], y_train, epochs=10)\n",
    "accuracy = ensemble_model.evaluate([X_test, X_test], y_test)[1]\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "2568b31422f911d240befaa5e46dd782c4cc23ae238e6e2196b9786beeefb2a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
